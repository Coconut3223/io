<!DOCTYPE html>

<html lang="zh-CN" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../_static/javascripts/modernizr.js"></script>
  
  
  
    <title>pytorch &#8212; HomePage</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=83e35b93" />
    <link rel="stylesheet" type="text/css" href="../_static/material.css?v=79c92029" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/css/rtd_sphinx_search.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/def.css?v=5a9d86bd" />
    <script src="../_static/documentation_options.js?v=7d86a446"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=6dbb43f8"></script>
    <script src="../_static/translations.js?v=beaddf03"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../_static/js/rtd_search_config.js"></script>
    <script src="../_static/js/rtd_sphinx_search.min.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="笔面" href="exam.html" />
    <link rel="prev" title="Numpy &amp; Scipy" href="numpy.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=blue data-md-color-accent=cyan>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#python/pytorch" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../index.html" title="HomePage"
           class="md-header-nav__button md-logo">
          
            <i class="md-icon">&#xe869</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">Cocobook</span>
          <span class="md-header-nav__topic"> pytorch </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder=""Search""
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/Coconut3223/io/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    io
  </div>
</a>
          </div>
        </div>
      
      
    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
          <li class="md-tabs__item"><a href="../index.html" class="md-tabs__link">HomePage</a></li>
            
            <li class="md-tabs__item"><a href="../AI/index.html" class="md-tabs__link">AI</a></li>
            
            <li class="md-tabs__item"><a href="index.html" class="md-tabs__link">Python</a></li>
            
            <li class="md-tabs__item"><a href="../NLP/index.html" class="md-tabs__link">NLP</a></li>
            
            <li class="md-tabs__item"><a href="../SQL/index.html" class="md-tabs__link">SQL</a></li>
            
            <li class="md-tabs__item"><a href="../utils/index.html" class="md-tabs__link">Utils</a></li>
            
            <li class="md-tabs__item"><a href="../frontend/index.html" class="md-tabs__link">Frontend</a></li>
          <li class="md-tabs__item"><a href="index.html" class="md-tabs__link">Python</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../index.html" title="HomePage" class="md-nav__button md-logo">
      
        <i class="md-icon">&#xe869</i>
      
    </a>
    <a href="../index.html"
       title="HomePage">Cocobook</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/Coconut3223/io/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    io
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">Content</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../AI/index.html" class="md-nav__link">AI</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../AI/ML/index.html" class="md-nav__link">ML</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../AI/DL/index.html" class="md-nav__link">DL</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../CV/index.html" class="md-nav__link">CV</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../NLP/index.html" class="md-nav__link">NLP</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="index.html" class="md-nav__link">python</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="elegant.html" class="md-nav__link">Elegant Python</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="enhanced.html" class="md-nav__link">Enhanced Python</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="numpy.html" class="md-nav__link">Numpy & Scipy</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    <label class="md-nav__link md-nav__link--active" for="__toc"> pytorch </label>
    
      <a href="#" class="md-nav__link md-nav__link--active">pytorch</a>
      
        
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">"Contents"</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#python-pytorch--page-root" class="md-nav__link">pytorch</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#configuration" class="md-nav__link">Configuration</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#id1" class="md-nav__link">pytorch 安装</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#concept" class="md-nav__link">concept</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#autograd" class="md-nav__link">Autograd</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#locally-disable-gradient-computation" class="md-nav__link">locally disable gradient computation</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#id2" class="md-nav__link">完整的</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#cpu-gpu" class="md-nav__link">cpu & gpu</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#gpu" class="md-nav__link">多gpu</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#id3" class="md-nav__link">训练和测试的不同</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#data" class="md-nav__link">Data</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#tensor" class="md-nav__link">Tensor</a>
        </li>
        <li class="md-nav__item"><a href="#class-dataset" class="md-nav__link">class DataSet</a>
        </li>
        <li class="md-nav__item"><a href="#datalodar" class="md-nav__link">Datalodar</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#nn" class="md-nav__link">nn</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#id4" class="md-nav__link">一些基本的东西</a>
        </li>
        <li class="md-nav__item"><a href="#containers-nn" class="md-nav__link"><cite>Containers</cite>  负责 nn 框架的构建</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#module-nn-base-class" class="md-nav__link"><cite>Module</cite> 所有 NN 的 base class</a>
        </li>
        <li class="md-nav__item"><a href="#sequential-transforms-compose" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">Sequential</span></code> 类 <code class="docutils literal notranslate"><span class="pre">transforms.Compose</span></code> 的用法，模型进一步封装</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#nn-xxx-nn-functional-xxx" class="md-nav__link">nn.xxx & nn.functional.xxx</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#liner" class="md-nav__link">Liner</a>
        </li>
        <li class="md-nav__item"><a href="#conv" class="md-nav__link">Conv</a>
        </li>
        <li class="md-nav__item"><a href="#pool" class="md-nav__link">Pool</a>
        </li>
        <li class="md-nav__item"><a href="#activation" class="md-nav__link">activation</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#softmax" class="md-nav__link">softmax</a>
        </li>
        <li class="md-nav__item"><a href="#relu-rectified-linear-unit" class="md-nav__link">ReLU, rectified linear unit</a>
        </li>
        <li class="md-nav__item"><a href="#sigmoid" class="md-nav__link">Sigmoid</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#normalization" class="md-nav__link">Normalization</a>
        </li>
        <li class="md-nav__item"><a href="#droupout" class="md-nav__link">Droupout</a>
        </li>
        <li class="md-nav__item"><a href="#flatten" class="md-nav__link"><cite>flatten</cite></a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#torch-nn-loss-torch-optim" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">torch.nn.</span></code> Loss & <code class="docutils literal notranslate"><span class="pre">torch.Optim</span></code></a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#torch-optim" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">torch.optim</span></code></a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#adam" class="md-nav__link">Adam</a>
        </li>
        <li class="md-nav__item"><a href="#sgd" class="md-nav__link">SGD 随机梯度下降</a>
        </li>
        <li class="md-nav__item"><a href="#adagrad" class="md-nav__link">Adagrad, 自适应随机梯度下降</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#torch-nn-loss" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">torch.nn.</span></code> Loss</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#l1loss-mae" class="md-nav__link">L1Loss, MAE</a>
        </li>
        <li class="md-nav__item"><a href="#mse" class="md-nav__link">MSE</a>
        </li>
        <li class="md-nav__item"><a href="#celoss" class="md-nav__link">CELoss</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#save-load" class="md-nav__link">Save & Load</a>
        </li>
        <li class="md-nav__item"><a href="#representation" class="md-nav__link">representation</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#utils-tensorboard" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">utils.tensorboard</span></code></a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#cv" class="md-nav__link">CV</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#transforms" class="md-nav__link">transforms</a>
        </li>
        <li class="md-nav__item"><a href="#models" class="md-nav__link">models</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#vgg16" class="md-nav__link">vgg16</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
  </ul>
</nav>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="#concept" class="md-nav__link">concept</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="exam.html" class="md-nav__link">笔面</a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../SQL/index.html" class="md-nav__link">SQL</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../utils/index.html" class="md-nav__link">utils</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../frontend/index.html" class="md-nav__link">frontend</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">"Contents"</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#python-pytorch--page-root" class="md-nav__link">pytorch</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#configuration" class="md-nav__link">Configuration</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#id1" class="md-nav__link">pytorch 安装</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#concept" class="md-nav__link">concept</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#autograd" class="md-nav__link">Autograd</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#locally-disable-gradient-computation" class="md-nav__link">locally disable gradient computation</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#id2" class="md-nav__link">完整的</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#cpu-gpu" class="md-nav__link">cpu & gpu</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#gpu" class="md-nav__link">多gpu</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#id3" class="md-nav__link">训练和测试的不同</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#data" class="md-nav__link">Data</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#tensor" class="md-nav__link">Tensor</a>
        </li>
        <li class="md-nav__item"><a href="#class-dataset" class="md-nav__link">class DataSet</a>
        </li>
        <li class="md-nav__item"><a href="#datalodar" class="md-nav__link">Datalodar</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#nn" class="md-nav__link">nn</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#id4" class="md-nav__link">一些基本的东西</a>
        </li>
        <li class="md-nav__item"><a href="#containers-nn" class="md-nav__link"><cite>Containers</cite>  负责 nn 框架的构建</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#module-nn-base-class" class="md-nav__link"><cite>Module</cite> 所有 NN 的 base class</a>
        </li>
        <li class="md-nav__item"><a href="#sequential-transforms-compose" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">Sequential</span></code> 类 <code class="docutils literal notranslate"><span class="pre">transforms.Compose</span></code> 的用法，模型进一步封装</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#nn-xxx-nn-functional-xxx" class="md-nav__link">nn.xxx & nn.functional.xxx</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#liner" class="md-nav__link">Liner</a>
        </li>
        <li class="md-nav__item"><a href="#conv" class="md-nav__link">Conv</a>
        </li>
        <li class="md-nav__item"><a href="#pool" class="md-nav__link">Pool</a>
        </li>
        <li class="md-nav__item"><a href="#activation" class="md-nav__link">activation</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#softmax" class="md-nav__link">softmax</a>
        </li>
        <li class="md-nav__item"><a href="#relu-rectified-linear-unit" class="md-nav__link">ReLU, rectified linear unit</a>
        </li>
        <li class="md-nav__item"><a href="#sigmoid" class="md-nav__link">Sigmoid</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#normalization" class="md-nav__link">Normalization</a>
        </li>
        <li class="md-nav__item"><a href="#droupout" class="md-nav__link">Droupout</a>
        </li>
        <li class="md-nav__item"><a href="#flatten" class="md-nav__link"><cite>flatten</cite></a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#torch-nn-loss-torch-optim" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">torch.nn.</span></code> Loss & <code class="docutils literal notranslate"><span class="pre">torch.Optim</span></code></a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#torch-optim" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">torch.optim</span></code></a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#adam" class="md-nav__link">Adam</a>
        </li>
        <li class="md-nav__item"><a href="#sgd" class="md-nav__link">SGD 随机梯度下降</a>
        </li>
        <li class="md-nav__item"><a href="#adagrad" class="md-nav__link">Adagrad, 自适应随机梯度下降</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#torch-nn-loss" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">torch.nn.</span></code> Loss</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#l1loss-mae" class="md-nav__link">L1Loss, MAE</a>
        </li>
        <li class="md-nav__item"><a href="#mse" class="md-nav__link">MSE</a>
        </li>
        <li class="md-nav__item"><a href="#celoss" class="md-nav__link">CELoss</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#save-load" class="md-nav__link">Save & Load</a>
        </li>
        <li class="md-nav__item"><a href="#representation" class="md-nav__link">representation</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#utils-tensorboard" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">utils.tensorboard</span></code></a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#cv" class="md-nav__link">CV</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#transforms" class="md-nav__link">transforms</a>
        </li>
        <li class="md-nav__item"><a href="#models" class="md-nav__link">models</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#vgg16" class="md-nav__link">vgg16</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <section id="pytorch">
<h1 id="python-pytorch--page-root">pytorch<a class="headerlink" href="#python-pytorch--page-root" title="Link to this heading">¶</a></h1>
<section id="configuration">
<h2 id="configuration">Configuration<a class="headerlink" href="#configuration" title="Link to this heading">¶</a></h2>
<section id="id1">
<h3 id="id1">pytorch 安装<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h3>
<ol class="arabic simple">
<li><p>是否有显卡驱动</p></li>
</ol>
<p><code class="docutils literal notranslate"><span class="pre">任务管理器</span></code> 看 GPU 一般是 NVIDIA 的。</p>
<ol class="arabic simple">
<li><p>[pytorch downlaod]</p>
<ul class="simple">
<li><dl class="simple">
<dt>[pytorch V.S.cuda] 查显卡决定pytorch</dt><dd><p>&lt;kbd&gt;nvidia-smi&lt;/kbd&gt;  cmds查看显卡情况</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>[pytorch V.S.python] 查pytorch 决定python虚拟环境</dt><dd><p>&lt;kbd&gt;conda create -n env_name python=? &lt;/kbd&gt;</p>
</dd>
</dl>
</li>
<li><p>查架构</p></li>
</ul>
</li>
</ol>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">查看架构</span><a class="headerlink" href="#id5" title="Link to this code">¶</a></div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">platfrorm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">platform</span><span class="o">.</span><span class="n">uname</span><span class="p">()[</span><span class="mi">4</span><span class="p">])</span>
<span class="go">arm64</span>
</pre></div>
</div>
</div>
<a class="reference internal image-reference" href="../_images/torch_download_1.png"><img alt="../_images/torch_download_1.png" src="../_images/torch_download_1.png" style="width: 520.8px; height: 200.4px;"/>
</a>
<a class="reference internal image-reference" href="../_images/torch_download_2.png"><img alt="../_images/torch_download_2.png" src="../_images/torch_download_2.png" style="width: 523.1999999999999px; height: 211.79999999999998px;"/>
</a>
<ol class="arabic">
<li><p>check</p>
<blockquote>
<div><div class="literal-block-wrapper docutils container" id="id6">
<div class="code-block-caption"><span class="caption-text">检查安装成功</span><a class="headerlink" href="#id6" title="Link to this code">¶</a></div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">torchvision</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">())</span> <span class="c1"># windows</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">())</span> <span class="c1"># mac</span>
<span class="go">True : ok</span>
</pre></div>
</div>
</div>
</div></blockquote>
</li>
</ol>
<div class="admonition-torch-cuda-is-avaliable-false admonition danger">
<p class="admonition-title"><code class="docutils literal notranslate"><span class="pre">torch.cuda.is_avaliable()</span></code> -&gt; False</p>
<ol class="arabic simple">
<li><p>检查 platform 是哪个</p></li>
<li><p>检查 gpu 是否支持cuda</p></li>
<li><p>检查显卡驱动版本</p></li>
<li><p>检查更新是否成功</p></li>
</ol>
</div>
</section>
</section>
</section>
<section id="concept">
<h1 id="concept">concept<a class="headerlink" href="#concept" title="Link to this heading">¶</a></h1>
<section id="autograd">
<h2 id="autograd">Autograd<a class="headerlink" href="#autograd" title="Link to this heading">¶</a></h2>
<div class="admonition-notes admonition note">
<p class="admonition-title">notes</p>
<p>Conceptually, autograd <span class="defi">records a graph</span> recording all of the operations that created the data as you execute operations, giving you <span class="defi">a directed acyclic graph whose leaves are the input tensors and roots are the output tensors</span> . By tracing this graph from roots to leaves, you can automatically compute the gradients using the chain rule.</p>
</div>
<section id="locally-disable-gradient-computation">
<h3 id="locally-disable-gradient-computation">locally disable gradient computation<a class="headerlink" href="#locally-disable-gradient-computation" title="Link to this heading">¶</a></h3>
</section>
</section>
<section id="id2">
<h2 id="id2">完整的<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h2>
<div class="admonition- admonition note">
<p class="admonition-title">初步检查模型是否有写错</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>model = MyModel()
input = torch.ones(batch, input_size)
output = model(input)
print(output.shape())</p>
</div>
<section id="cpu-gpu">
<h3 id="cpu-gpu">cpu &amp; gpu<a class="headerlink" href="#cpu-gpu" title="Link to this heading">¶</a></h3>
<div class="admonition-gpu admonition danger">
<p class="admonition-title">要放进gpu的是</p>
<ol class="arabic simple">
<li><p>model</p></li>
<li><p>损失函数</p></li>
<li><p>数据（X，label）</p></li>
</ol>
</div>
<p><span class="defi">使用方法</span></p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="sd">"""</span>
<span class="hll"><span class="sd">    :meth1: .cuda()</span>
</span><span class="sd">    但要注意 gpu 是否可用</span>
<span class="sd">"""</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
    <span class="n">imgs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">data</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">imgs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">targets</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="sd">"""</span>
<span class="hll"><span class="sd">    :meth2: .to(device)</span>
</span><span class="sd">"""</span>
<span class="hll"><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span><span class="p">)</span>
</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">loss_fn</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
    <span class="n">imgs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">imgs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<section id="gpu">
<h4 id="gpu">多gpu<a class="headerlink" href="#gpu" title="Link to this heading">¶</a></h4>
<ol class="arabic simple">
<li><p>选择一个运行</p></li>
</ol>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda'</span><span class="p">)</span> <span class="c1"># default = 第一块</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda:0'</span><span class="p">)</span> <span class="c1"># 第一块</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda:1'</span><span class="p">)</span> <span class="c1"># 第二块</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>多gpu运行</p></li>
</ol>
</section>
</section>
<section id="id3">
<h3 id="id3">训练和测试的不同<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h3>
<div class="admonition-with-torch-no-grad admonition note">
<p class="admonition-title">当不涉及训练时： <code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">torch.no_grad():</span></code></p>
<div class="line-block">
<div class="line">反向传播的时候需要 tensor 的 <code class="docutils literal notranslate"><span class="pre">requires_grad=True</span></code> 才能自动求导，从而优化参数。这其中涉及 <span class="defi">求导图</span> 即内存的消耗</div>
<div class="line">但是训练的时候不需要求导，在 <code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">torch.no_grad():</span></code> 下，所有计算得出的 tensor 的 requires_grad都自动设置为 False。</div>
<div class="line">[【pytorch系列】 with torch.no_grad():用法详解]</div>
</div>
</div>
<div class="admonition-model-train-model-eval admonition note">
<p class="admonition-title"><cite>model.train()</cite> &amp; <cite>model.eval()</cite></p>
<p>class:<cite>Dropout</cite>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,etc.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model.train()</span></code> 写在模型训练前</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model.eval()``==``module.train(False)</span></code> 写在模型测试前</p></li>
</ul>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
<span class="hll">    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span>    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">traning_loader</span><span class="p">:</span>
        <span class="o">...</span>

<span class="hll">    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span>    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">testing_loader</span><span class="p">:</span>
        <span class="o">...</span>
</pre></div>
</div>
</div>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span> <span class="n">T</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
</span><span class="w">    </span><span class="sd">"""</span>
<span class="sd">    把模型调到 training mode.</span>

<span class="sd">    Args:</span>
<span class="sd">        - mode: Bool</span>
<span class="sd">            default = True = 训练模式</span>
<span class="sd">            - False = 测评模式</span>
<span class="sd">    """</span>
        <span class="o">...</span>
    <span class="k">return</span> <span class="bp">self</span>

<span class="hll"><span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span> <span class="n">T</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
</span><span class="w">    </span><span class="sd">"""</span>
<span class="sd">    把模型调到 evaluation mode</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="data">
<h2 id="data">Data<a class="headerlink" href="#data" title="Link to this heading">¶</a></h2>
<section id="tensor">
<h3 id="tensor">Tensor<a class="headerlink" href="#tensor" title="Link to this heading">¶</a></h3>
</section>
<section id="class-dataset">
<h3 id="class-dataset">class DataSet<a class="headerlink" href="#class-dataset" title="Link to this heading">¶</a></h3>
<div class="admonition-torch-utils-data-dataset admonition note">
<p class="admonition-title">官方 <code class="docutils literal notranslate"><span class="pre">torch.utils.data.DataSet</span></code></p>
<p>一个虚拟的类，All datasets that represent a map from keys to data samples</p>
<ul class="simple">
<li><dl class="simple">
<dt>所有的 dataset 都必须继承它</dt><dd><ol class="arabic simple">
<li><p>必须重写 <cite>__getitem__</cite></p></li>
<li><p>选择重写 <cite>__len__</cite></p></li>
<li><p>如果 key/indice 不是 int，对应的 DataLoader 也大改</p></li>
</ol>
</dd>
</dl>
</li>
</ul>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Dataset</span><span class="p">(</span><span class="n">Generic</span><span class="p">[</span><span class="n">T_co</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    设立数据集，包括 key/indice(default int)、data、label</span>
<span class="sd">    要能通过 key/indice 来访问对应的 data 和 label</span>
<span class="sd">    如果 key/indice 不是 int，对应的 DataLoader 也要大改</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T_co</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="fm">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s1">'Dataset[T_co]'</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">'ConcatDataset[T_co]'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ConcatDataset</span><span class="p">([</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">])</span>

    <span class="c1"># No `def __len__(self)` default?</span>
    <span class="c1"># See NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]</span>
    <span class="c1"># in pytorch/torch/utils/data/sampler.py</span>
</pre></div>
</div>
</div>
</section>
<section id="datalodar">
<h3 id="datalodar">Datalodar<a class="headerlink" href="#datalodar" title="Link to this heading">¶</a></h3>
<div class="admonition-torch-utils-data-dataloader admonition note">
<p class="admonition-title"><code class="docutils literal notranslate"><span class="pre">torch.utils.data.DataLoader</span></code></p>
<p>constructs a index sampler that yields integral indices</p>
</div>
<div class="line-block">
<div class="line">Epoch: 所有训练样本都以输入到模型中，称为一个Epoch</div>
<div class="line">Iteration: 一批样本输入到模型中，为一个Iteration</div>
<div class="line">Batchsize: 批大小，主要是决定一个Epoch有多少个Iteration</div>
</div>
<p>样本81， Batchsize=8;</p>
<p>1 Epoch = 10  drop_last=True
1 Epoch = 11  drop_last=False</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="k">class</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">Generic</span><span class="p">[</span><span class="n">T_co</span><span class="p">]):</span>
</span><span class="w">    </span><span class="sd">"""</span>
<span class="sd">    “抽样式”地少量 batch 加载数据，集 “数据集 dataset”， “抽样 sampler”，</span>
<span class="sd">    “迭代器 iterator” 于一体。可以 单或者多进程 来加载</span>

<span class="sd">    Args:</span>
<span class="sd">        - dataset: torch.DataSet</span>
<span class="sd">        - batch_size: Optional[int] = samples per batch</span>
<span class="sd">            default = 1</span>
<span class="sd">        - shuffle: Optional[bool] = 在每个 epoch 开始的时候，对数据进行重新排序</span>
<span class="sd">            default = False</span>
<span class="sd">        - sampler: Union[Sampler, Iterable, None] = 自定义从数据集中取样本的策略</span>
<span class="sd">            default = None</span>
<span class="sd">            根据 dataset 的性质来决定</span>
<span class="sd">            和 shuffle 互斥</span>
<span class="sd">        - batch_sampler: Union[Sampler[Sequence], Iterable[Sequence], None]</span>
<span class="sd">            =  与sampler类似，返回 batch 的 indice</span>
<span class="sd">            default = None</span>
<span class="sd">            和 batch_size, shuffle, sampler, drop_last 互斥</span>
<span class="sd">        - num_workers: int = 有多少个子进程</span>
<span class="sd">            default = 0 只有 main process</span>
<span class="sd">        - drop_last: bool = 除不尽时候，要不要的最后一个 batch</span>
<span class="sd">            default = False</span>
<span class="sd">        - generator: torch.Generator</span>
<span class="sd">            default = None</span>

<span class="sd">    Warning:</span>
<span class="sd">        - iterable-style datasets are incompatible with custom samplers first</span>
<span class="sd">        - 设置了 batch_sampler，那么batch_size,shuffle,sampler,drop_last</span>
<span class="sd">        就不能再制定了</span>
<span class="sd">    """</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">[</span><span class="n">T_co</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sampler</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_sampler</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sampler</span><span class="p">[</span><span class="n">Sequence</span><span class="p">],</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Sequence</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">collate_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_collate_fn_t</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">timeout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">worker_init_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_worker_init_fn_t</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">multiprocessing_context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span> <span class="n">prefetch_factor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">persistent_workers</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">pin_memory_device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">""</span><span class="p">):</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Warning:</span>
<span class="sd">            - `IterableDataset` 会 不正确 ！！！</span>
<span class="sd">            - Cannot statically verify that dataset is Sized</span>
<span class="sd">            - 往上取整， 考虑 droplast</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataset_kind</span> <span class="o">==</span> <span class="n">_DatasetKind</span><span class="o">.</span><span class="n">Iterable</span><span class="p">:</span>

            <span class="n">length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_IterableDataset_len_called</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
            <span class="c1"># type: ignore[assignment, arg-type]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># IterableDataset doesn't allow custom sampler or batch_sampler</span>
                <span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">ceil</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_last</span><span class="p">:</span>
                    <span class="n">length</span> <span class="o">=</span> <span class="n">length</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">length</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">length</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">length</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_index_sampler</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="nn">
<h2 id="nn">nn<a class="headerlink" href="#nn" title="Link to this heading">¶</a></h2>
<section id="id4">
<h3 id="id4">一些基本的东西<a class="headerlink" href="#id4" title="Link to this heading">¶</a></h3>
</section>
<section id="containers-nn">
<h3 id="containers-nn"><cite>Containers</cite>  负责 nn 框架的构建<a class="headerlink" href="#containers-nn" title="Link to this heading">¶</a></h3>
<section id="module-nn-base-class">
<h4 id="module-nn-base-class"><cite>Module</cite> 所有 NN 的 base class<a class="headerlink" href="#module-nn-base-class" title="Link to this heading">¶</a></h4>
<p>可以包括其他的 module. Modules can also contain other Modules, allowing to nest them in a tree structure.</p>
<div class="admonition-nn-defi-subclass-init admonition danger">
<p class="admonition-title">所有 NN 模型都要 <span class="defi">继承 subclass</span> 它，并且要先 父类的 init</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="hll">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">con2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">mymodel</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">mymodel</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Module</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    所有 nn 模型的 base class 都要继承它</span>
<span class="sd">    """</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Initializes internal Module state, shared by both nn.Module and ScriptModule.</span>

<span class="sd">        Warning:</span>
<span class="sd">            - 如果改属性 最好用 `` super().__setattr__('a', a) ``</span>
<span class="sd">                而不是 `` self.a = a `` 防止 Module.__setattr__ overhead</span>
<span class="sd">        """</span>
        <span class="o">...</span>
</pre></div>
</div>
</section>
<section id="sequential-transforms-compose">
<h4 id="sequential-transforms-compose"><code class="docutils literal notranslate"><span class="pre">Sequential</span></code> 类 <code class="docutils literal notranslate"><span class="pre">transforms.Compose</span></code> 的用法，模型进一步封装<a class="headerlink" href="#sequential-transforms-compose" title="Link to this heading">¶</a></h4>
<div class="admonition-torch-nn-sequential-torch-nn-modulelist admonition note">
<p class="admonition-title"><code class="docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code> 和 <code class="docutils literal notranslate"><span class="pre">torch.nn.ModuleList</span></code> 的区别”</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">torch.nn.ModuleList</span></code> 就是真的一个储存模型的list</p></li>
</ul>
</div>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Sequential</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    模型的序列封装，输入会按序经过里面的每一个模型，最后进行输出。</span>
<span class="sd">    把所有的模型都封装 as a single module</span>
<span class="sd">    如果不用 OrderedDict, 那么 str(index) 作为 key</span>
<span class="sd">    可以通过 index 也可以通过 key 来 access</span>

<span class="sd">    Meth:</span>
<span class="sd">        - .pop(key)</span>
<span class="sd">        - .append()</span>
<span class="sd">        - .extend(Sequential)</span>
<span class="sd">        - .insert(index, Module)</span>
<span class="sd">        - del(model)</span>
<span class="sd">        - = model1 + model 2</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; # 按顺序经过 Conv2d(1,20,5) - ReLU - Conv2d(20,64,5) - ReLU</span>
<span class="hll"><span class="sd">        &gt;&gt;&gt; model = nn.Sequential(</span>
</span><span class="sd">                nn.Conv2d(1,20,5),</span>
<span class="sd">                nn.ReLU(),</span>
<span class="sd">                nn.Conv2d(20,64,5),</span>
<span class="sd">                nn.ReLU())</span>
<span class="sd">        &gt;&gt;&gt; print(model)</span>
<span class="sd">        # Sequential(</span>
<span class="sd">            (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))</span>
<span class="sd">            (1): ReLU()</span>
<span class="sd">            (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))</span>
<span class="sd">            (3): ReLU())</span>
<span class="sd">        &gt;&gt;&gt; print(model[-1])</span>
<span class="sd">        # ReLU()</span>
<span class="hll"><span class="sd">        &gt;&gt;&gt; model.pop(-1) # 和 stack 不一样，必须传 index 或 key</span>
</span><span class="sd">        # ReLU()</span>
<span class="sd">        &gt;&gt;&gt; print(model)</span>
<span class="sd">        # Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))</span>
<span class="hll"><span class="sd">        &gt;&gt;&gt; model[-1] = ReLU()</span>
</span><span class="hll"><span class="sd">        &gt;&gt;&gt; del(model[0])</span>
</span><span class="hll"><span class="sd">        &gt;&gt;&gt; model.append(Liner(10, 3)</span>
</span><span class="sd">        # Sequential(</span>
<span class="sd">            (0): ReLU()</span>
<span class="sd">            (1): ReLU()</span>
<span class="sd">            (2): Linear(10, 3)</span>
<span class="sd">        -------------------------------------------</span>
<span class="sd">        &gt;&gt;&gt; # Using Sequential with OrderedDict.</span>
<span class="sd">        &gt;&gt;&gt; from collections import OrderedDict</span>
<span class="hll"><span class="sd">        &gt;&gt;&gt; model = nn.Sequential(OrderedDict([</span>
</span><span class="sd">                ('conv1', nn.Conv2d(1,20,5)),</span>
<span class="sd">                ('relu1', nn.ReLU()),</span>
<span class="sd">                ('conv2', nn.Conv2d(20,64,5)),</span>
<span class="sd">                ('relu2', nn.ReLU())</span>
<span class="sd">                ]))</span>
<span class="sd">        &gt;&gt;&gt; print(model)</span>
<span class="sd">        # Sequential(</span>
<span class="sd">            (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))</span>
<span class="sd">            (relu1): ReLU()</span>
<span class="sd">            (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))</span>
<span class="sd">            (relu2): ReLU())</span>
<span class="sd">    """</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">OrderedDict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">),</span> <span class="n">module</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">module</span><span class="p">:</span> <span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">""" model[idx] = Linear(in, out) """</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_item_by_idx</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">idx</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__delitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">slice</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">""" del(model[idx]) """</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="n">idx</span><span class="p">]:</span>
                <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_item_by_idx</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">idx</span><span class="p">)</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
        <span class="c1"># To preserve numbering</span>
        <span class="n">str_indices</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">str_indices</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">())))</span>

    <span class="k">def</span> <span class="fm">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">'Sequential'</span><span class="p">:</span>
<span class="w">        </span><span class="sd">""" model = model1 + model2 """</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Sequential</span><span class="p">):</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
                <span class="n">ret</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">other</span><span class="p">:</span>
                <span class="n">ret</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">ret</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'add operator supports only objects '</span>
                            <span class="s1">'of Sequential class, but </span><span class="si">{}</span><span class="s1"> is given.'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">other</span><span class="p">))))</span>

    <span class="k">def</span> <span class="nf">pop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">slice</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Module</span><span class="p">:</span>
<span class="w">        </span><span class="sd">""" model.pop(key) """</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">del</span> <span class="bp">self</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">v</span>

    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">input</span>

    <span class="k">def</span> <span class="nf">append</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">:</span> <span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">'Sequential'</span><span class="p">:</span>
<span class="w">        </span><span class="sd">""" module.append(nn.Module) """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)),</span> <span class="n">module</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">insert</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">module</span><span class="p">:</span> <span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">'Sequential'</span><span class="p">:</span>
<span class="w">        </span><span class="sd">""" model.insert(nn.Module)"""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">Module</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span>
                <span class="s1">'module should be of type: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">Module</span><span class="p">))</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="o">-</span><span class="n">n</span> <span class="o">&lt;=</span> <span class="n">index</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span>
                <span class="s1">'Index out of range: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">index</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">index</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">+=</span> <span class="n">n</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">index</span><span class="p">)]</span> <span class="o">=</span> <span class="n">module</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">extend</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequential</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">'Sequential'</span><span class="p">:</span>
<span class="w">        </span><span class="sd">""" model.extend(model1) """</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">sequential</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>
</pre></div>
</div>
</section>
</section>
<section id="nn-xxx-nn-functional-xxx">
<h3 id="nn-xxx-nn-functional-xxx">nn.xxx &amp; nn.functional.xxx<a class="headerlink" href="#nn-xxx-nn-functional-xxx" title="Link to this heading">¶</a></h3>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="n">inport</span> <span class="n">Functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">layer_nn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">layer_F</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<section id="liner">
<h4 id="liner">Liner<a class="headerlink" href="#liner" title="Link to this heading">¶</a></h4>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    h = W^Tx+b</span>

<span class="sd">    Args:</span>
<span class="sd">        - in_features: Int = 入</span>
<span class="sd">        - out_features: Int = 出</span>
<span class="sd">        - bias: Bool</span>
<span class="sd">            default = True</span>

<span class="sd">    Attributes:</span>
<span class="sd">        - weight: tensor[in_features, out_features]</span>
<span class="sd">        - bias: tensor[1]</span>

<span class="sd">    Examples::</span>
<span class="sd">        &gt;&gt;&gt; m = nn.Linear(20, 30)</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(128, 20)</span>
<span class="sd">        &gt;&gt;&gt; output = m(input)</span>
<span class="sd">        &gt;&gt;&gt; print(output.size())</span>
<span class="sd">        #res: torch.Size([128, 30])</span>
<span class="sd">    """</span>

    <span class="o">...</span>
</pre></div>
</div>
</section>
<section id="conv">
<h4 id="conv">Conv<a class="headerlink" href="#conv" title="Link to this heading">¶</a></h4>
<div class="math">
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">U</mi><mo stretchy="false">(</mo><mo>−</mo><msqrt><mi>k</mi></msqrt><mo separator="true">,</mo><msqrt><mi>k</mi></msqrt><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mi>k</mi><mo>=</mo><mfrac><mrow><mi>g</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mi>s</mi></mrow><mrow><msub><mi>C</mi><mtext>in</mtext></msub><mo>∗</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mn>1</mn></munderover><mtext>kernel_size</mtext><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\mathcal{U}(-\sqrt{k}, \sqrt{k})
\\
k = \frac{groups}{C_\text{in} * \prod_{i=0}^{1}\text{kernel\_size}[i]}

</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.2311em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.09931em;">U</span><span class="mopen">(</span><span class="mord">−</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9811em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span><span style="top:-2.9411em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg height="1.08em" preserveaspectratio="xMinYMin slice" viewbox="0 0 400000 1080" width="400em" xmlns="http://www.w3.org/2000/svg"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.0589em;"><span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9811em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span><span style="top:-2.9411em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg height="1.08em" preserveaspectratio="xMinYMin slice" viewbox="0 0 400000 1080" width="400em" xmlns="http://www.w3.org/2000/svg"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.0589em;"><span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2616em;vertical-align:-1.154em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1076em;"><span style="top:-2.156em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3175em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∏</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.954em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord">kernel_size</span></span><span class="mopen">[</span><span class="mord mathnormal">i</span><span class="mclose">]</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">ro</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.154em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div><div class="math">
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>out</mtext><mo stretchy="false">(</mo><msub><mi>N</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>C</mi><msub><mtext>out</mtext><mi>j</mi></msub></msub><mo stretchy="false">)</mo><mo>=</mo><mtext>bias</mtext><mo stretchy="false">(</mo><msub><mi>C</mi><msub><mtext>out</mtext><mi>j</mi></msub></msub><mo stretchy="false">)</mo><mo>+</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><msub><mi>C</mi><mtext>in</mtext></msub><mo>−</mo><mn>1</mn></mrow></munderover><mtext>weight</mtext><mo stretchy="false">(</mo><msub><mi>C</mi><msub><mtext>out</mtext><mi>j</mi></msub></msub><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">)</mo><mo>⋆</mo><mtext>input</mtext><mo stretchy="false">(</mo><msub><mi>N</mi><mi>i</mi></msub><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mrow><mo fence="true">{</mo><mtable columnalign="left left" columnspacing="1em" rowspacing="0.36em"><mtr><mtd><mstyle displaystyle="false" scriptlevel="0"><mi>N</mi></mstyle></mtd><mtd><mstyle displaystyle="false" scriptlevel="0"><mtext>batch size</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="false" scriptlevel="0"><mi>C</mi></mstyle></mtd><mtd><mstyle displaystyle="false" scriptlevel="0"><mtext>channel</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="false" scriptlevel="0"><mi>H</mi></mstyle></mtd><mtd><mstyle displaystyle="false" scriptlevel="0"><mtext>height</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="false" scriptlevel="0"><mi>W</mi></mstyle></mtd><mtd><mstyle displaystyle="false" scriptlevel="0"><mtext>width</mtext></mstyle></mtd></mtr></mtable></mrow><mspace linebreak="newline"></mspace><msub><mi>H</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>=</mo><mrow><mo fence="true">⌊</mo><mfrac><mrow><msub><mi>H</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>+</mo><mn>2</mn><mo>×</mo><mtext>padding</mtext><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo><mo>−</mo><mtext>dilation</mtext><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo><mo>×</mo><mo stretchy="false">(</mo><mtext>kernel_size</mtext><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>−</mo><mn>1</mn></mrow><mrow><mtext>stride</mtext><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo></mrow></mfrac><mo>+</mo><mn>1</mn><mo fence="true">⌋</mo></mrow><mspace linebreak="newline"></mspace><msub><mi>W</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>=</mo><mrow><mo fence="true">⌊</mo><mfrac><mrow><msub><mi>W</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>+</mo><mn>2</mn><mo>×</mo><mtext>padding</mtext><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo><mo>−</mo><mtext>dilation</mtext><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo><mo>×</mo><mo stretchy="false">(</mo><mtext>kernel_size</mtext><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>−</mo><mn>1</mn></mrow><mrow><mtext>stride</mtext><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></mfrac><mo>+</mo><mn>1</mn><mo fence="true">⌋</mo></mrow></mrow><annotation encoding="application/x-tex">\text{out}(N_i, C_{\text{out}_j}) = \text{bias}(C_{\text{out}_j}) +
\sum_{k = 0}^{C_{\text{in}} - 1} \text{weight}(C_{\text{out}_j}, k) \star \text{input}(N_i, k)
\\\begin{cases} N&amp;\text{batch size}\\ C&amp;\text{channel}\\H&amp;\text{height}\\W&amp;\text{width}\\\end{cases}\\
H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] - \text{dilation}[0]
        \times (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor\\
W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] - \text{dilation}[1]
        \times (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1.0973em;vertical-align:-0.3473em;"></span><span class="mord text"><span class="mord">out</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">out</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3473em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0973em;vertical-align:-0.3473em;"></span><span class="mord text"><span class="mord">bias</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">out</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3473em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:3.1415em;vertical-align:-1.3021em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8394em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3111em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.334em;"><span style="top:-2.357em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">in</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord">weight</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">out</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3473em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋆</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">input</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:5.76em;vertical-align:-2.63em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.95em;"><span style="top:-1.6em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎩</span></span></span><span style="top:-1.592em;"><span class="pstrut" style="height:3.15em;"></span><span style="height:0.916em;width:0.8889em;"><svg height="0.916em" preserveaspectratio="xMinYMin" style="width:0.8889em" viewbox="0 0 888.89 916" width="0.8889em" xmlns="http://www.w3.org/2000/svg"><path d="M384 0 H504 V916 H384z M384 0 H504 V916 H384z"></path></svg></span></span><span style="top:-3.15em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎨</span></span></span><span style="top:-4.292em;"><span class="pstrut" style="height:3.15em;"></span><span style="height:0.916em;width:0.8889em;"><svg height="0.916em" preserveaspectratio="xMinYMin" style="width:0.8889em" viewbox="0 0 888.89 916" width="0.8889em" xmlns="http://www.w3.org/2000/svg"><path d="M384 0 H504 V916 H384z M384 0 H504 V916 H384z"></path></svg></span></span><span style="top:-5.2em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎧</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.45em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.13em;"><span style="top:-5.13em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span></span></span><span style="top:-0.81em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.63em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.13em;"><span style="top:-5.13em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">batch size</span></span></span></span><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">channel</span></span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">height</span></span></span></span><span style="top:-0.81em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">width</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.63em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">⌊</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">stride</span></span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.7em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0813em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord text"><span class="mord">dilation</span></span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mopen">(</span><span class="mord text"><span class="mord">kernel_size</span></span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">⌋</span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">⌊</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">stride</span></span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.7em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord text"><span class="mord">dilation</span></span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mopen">(</span><span class="mord text"><span class="mord">kernel_size</span></span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">⌋</span></span></span></span></span></span></span></div><div class="admonition-input-size admonition danger">
<p class="admonition-title">input size</p>
<p>nn 可以[B, C, H, W] 或 [C, H, W]
functional <span class="defi">只可以 [B, C, H, W]</span></p>
</div>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="n">_ConvNd</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="hll"><span class="sd">    nn.Conv2d</span>
</span>
<span class="sd">    Args:</span>
<span class="sd">        - in_channels: int = C_{in} = 输入的通道数</span>
<span class="sd">        - out_channels: int = C_{out} = 输出的通道数</span>
<span class="sd">        - kernel_size: Union[int. tuple(int)] (int or tuple) = 卷积核大小</span>
<span class="sd">        - stride: Union[int, tuple(int)] = 位移量</span>
<span class="sd">            default = 1</span>
<span class="sd">            - int = 竖直方向 = 水平方向</span>
<span class="sd">        - padding: Union[int, tuple(int), str\in{{'valid', 'same'}}] = 填充 input 图像</span>
<span class="sd">            default = 0</span>
<span class="sd">            - int = 竖直方向 = 水平方向</span>
<span class="sd">            - 'valid' = no padding</span>
<span class="sd">            - 'same' = 使得 input‘shape = output’shape</span>
<span class="sd">        - dilation: Union[int, tuple(int)]= 填充 kernel 卷积核,  Spacing between kernel elements</span>
<span class="sd">            default = 1 = no space</span>
<span class="sd">            详看理论部分</span>
<span class="sd">        - bias: bool 可学习的偏置</span>
<span class="sd">            default: ``True``</span>

<span class="sd">    Shape:</span>
<span class="sd">        - Input = (N, C_{in}, H_{in}, W_{in}) 或 (C_{in}, H_{in}, W_{in})</span>
<span class="sd">        - Output = (N, C_{out}, H_{out}, W_{out}) 或 (C_{out}, H_{out}, W_{out})</span>

<span class="sd">    Attributes:</span>
<span class="sd">        - weight: Tensor[...] = 学习出来的卷积核 kernel</span>
<span class="sd">            详看理论部分</span>
<span class="sd">        - bias: Tensor[out_channels] = 学习出来的偏置</span>
<span class="sd">            需要 bias := True</span>
<span class="sd">            详看理论部分</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # non-square kernels and unequal stride and with padding and dilation</span>
<span class="sd">        &gt;&gt;&gt; m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(20, 16, 50, 100)</span>
<span class="sd">        &gt;&gt;&gt; output = m(input)</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="p">:</span> <span class="n">_size_2_t</span><span class="p">,</span>
        <span class="n">stride</span><span class="p">:</span> <span class="n">_size_2_t</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">_size_2_t</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">dilation</span><span class="p">:</span> <span class="n">_size_2_t</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">padding_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">'zeros'</span><span class="p">,</span>  <span class="c1"># TODO: refine this type</span>
        <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="o">...</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size_</span><span class="p">,</span> <span class="n">stride_</span><span class="p">,</span> <span class="n">padding_</span><span class="p">,</span> <span class="n">dilation_</span><span class="p">,</span>
            <span class="kc">False</span><span class="p">,</span> <span class="n">_pair</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">groups</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>

    <span class="o">...</span>
</pre></div>
</div>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">conv2d</span> <span class="o">=</span> <span class="n">_add_docstr</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">conv2d</span><span class="p">,</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="hll"><span class="sd">    nn.funcational.conv2d</span>
</span>
<span class="sd">    conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -&gt; Tensor</span>

<span class="sd">    Args:</span>
<span class="sd">        - input: Tensor[minibatch, in_channels, in_H , in_W]</span>
<span class="sd">        - weight: Tensor[out_channels, ?, ke_H, ke_W] = 卷积核</span>
<span class="sd">        - bias: Union[Tensor[out_channels], None]</span>
<span class="sd">        - stride: Union[Int, Tuple(Int, Int)]</span>
<span class="sd">            default =  1</span>
<span class="sd">        - padding: Union[Int, Tuple(Int, Int), Str{'valid', 'same'}]</span>
<span class="sd">            default = 0</span>
<span class="sd">            - 'valid' = no padding</span>
<span class="sd">            - 'same' =</span>
<span class="sd">        - dilation: Union[Int, Tuple(Int, Int)] the spacing between kernel elements.</span>
<span class="sd">            default = 1</span>

<span class="sd">    Examples::</span>

<span class="sd">        &gt;&gt;&gt; # With square kernels and equal stride</span>
<span class="sd">        &gt;&gt;&gt; filters = torch.randn(8, 4, 3, 3)</span>
<span class="sd">        &gt;&gt;&gt; inputs = torch.randn(1, 4, 5, 5)</span>
<span class="sd">        &gt;&gt;&gt; F.conv2d(inputs, filters, padding=1)</span>
<span class="sd">    """</span>
<span class="p">)</span>
<span class="o">...</span>
</pre></div>
</div>
</section>
<section id="pool">
<h4 id="pool">Pool<a class="headerlink" href="#pool" title="Link to this heading">¶</a></h4>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="k">class</span> <span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">_MaxPoolNd</span><span class="p">):</span>
</span><span class="w">    </span><span class="sd">"""</span>
<span class="sd">    2D 最大池化</span>

<span class="sd">    Shape:</span>
<span class="sd">        - input = [N, C, in_H, in_W] 或 [C, in_H, in_W]</span>
<span class="sd">        - ouptput = [N, C, out_H, out_W] 或 [C, in_H, in_W]</span>
<span class="sd">        - kernel = [ke_H, ke_W]</span>
<span class="sd">        公式详看理论部分</span>

<span class="sd">    Args:</span>
<span class="sd">        - kernel_size: Union[Int, Tuple(Int, Int)]</span>
<span class="sd">        - stride: Union[Int, Tuple(Int, Int)]</span>
<span class="sd">            default = kernel_size !!!</span>
<span class="sd">        - padding: Union[Int, Tuple(Int, Int)] = 填充负无穷</span>
<span class="sd">            用来针对除不尽的情况，也不会影响到取值（MaxPool）</span>
<span class="sd">        - dilation: Union[Int, Tuple(Int, Int)] = controls the stride of elements in the window</span>
<span class="sd">        - return_indices: Bool = 返回 MaxPool 中被取值的索引</span>
<span class="sd">            default =</span>
<span class="sd">        - ceil_mode: Bool = 要不要边界料</span>
<span class="sd">            default = False</span>
<span class="sd">            - False = `floor` = 不要边角料</span>
<span class="sd">            - True = `ceil` = 要边角料 go off-bounds</span>
<span class="sd">            应对除不尽的情况， 详看理论部分</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; # pool of non-square window</span>
<span class="sd">        &gt;&gt;&gt; m = nn.MaxPool2d((3, 2), stride=(2, 1))</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(20, 16, 50, 32)</span>
<span class="sd">        &gt;&gt;&gt; output = m(input)</span>
<span class="sd">    """</span>

    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">,</span>
                            <span class="n">return_indices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">return_indices</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="activation">
<h4 id="activation">activation<a class="headerlink" href="#activation" title="Link to this heading">¶</a></h4>
<div class="admonition-non-inpalce admonition danger">
<p class="admonition-title">non-inpalce</p>
<p>shape：[B, *] 除了必须batchsize，后面 size 都随便</p>
</div>
<section id="softmax">
<h5 id="softmax">softmax<a class="headerlink" href="#softmax" title="Link to this heading">¶</a></h5>
<div class="math">
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Softmax</mtext><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><munder><mo>∑</mo><mi>j</mi></munder><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{Softmax}(x_{i}) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}

</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Softmax</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.5488em;vertical-align:-1.1218em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">exp</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1218em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div><ul class="simple">
<li><p>如果是稀疏向量 sparse vector（只传递非0的值），那些未传递的=原本是0的 在 softmax 里 看作  <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>inf</mi><mo>⁡</mo><mtext>，</mtext><mo>→</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mo>−</mo><mi>inf</mi><mo>⁡</mo><mo stretchy="false">)</mo><mo>→</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">-\inf，\rightarrow \text{softmax}(-\inf)\rightarrow0</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">in<span style="margin-right:0.07778em;">f</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord cjk_fallback">，</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">in<span style="margin-right:0.07778em;">f</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span></span></p></li>
</ul>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Softmax</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    将某一维的值 映射到[0, 1] &amp; sum=1。</span>

<span class="sd">    Shape:</span>
<span class="sd">        都可以</span>

<span class="sd">    Args:</span>
<span class="sd">        - dim: Int = 要进行 softmax 的维度</span>
<span class="sd">            default =</span>

<span class="sd">    Examples::</span>
<span class="sd">        &gt;&gt;&gt; one, zerp = nn.Softmax(dim=1), nn.Softmax(dim=0)</span>
<span class="sd">        &gt;&gt;&gt; input = torch.tensor([[-1., -1.],[2., 2.]])</span>
<span class="sd">        &gt;&gt;&gt; y1, y0 = one(input), zero(input)</span>
<span class="sd">        # y1 = tensor([[0.5, 0.5], [0.5, 0.5]])</span>
<span class="sd">        # y0 = tensor([[0.0474, 0.0474], [0.9526, 0.9526]])</span>
<span class="sd">    """</span>
    <span class="o">...</span>
</pre></div>
</div>
</section>
<section id="relu-rectified-linear-unit">
<h5 id="relu-rectified-linear-unit">ReLU, rectified linear unit<a class="headerlink" href="#relu-rectified-linear-unit" title="Link to this heading">¶</a></h5>
<div class="math">
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>ReLU</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mi>x</mi><msup><mo stretchy="false">)</mo><mo>+</mo></msup><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{ReLU}(x) = (x)^+ = \max(0, x)

</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">ReLU</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0713em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8213em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></div><img alt="https://pytorch.org/docs/stable/_images/ReLU.png" src="https://pytorch.org/docs/stable/_images/ReLU.png"/>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="k">class</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
</span><span class="w">    </span><span class="sd">"""</span>
<span class="sd">    对于0以下截断</span>

<span class="sd">    Args:</span>
<span class="sd">        - inplace:Bool = 原地实现</span>
<span class="sd">            default = False</span>

<span class="sd">    Shape:</span>
<span class="sd">        都可以</span>

<span class="sd">    Examples::</span>
<span class="sd">        &gt;&gt;&gt; m = nn.ReLU()</span>
<span class="sd">        &gt;&gt;&gt; input = torch.tensor([[-1., -1.],[2., 2.]])</span>
<span class="sd">        &gt;&gt;&gt; output = m(input)</span>
<span class="sd">        # output: tensor([[0., 0.], [2., 2.]])</span>
<span class="sd">    """</span>
    <span class="o">...</span>
</pre></div>
</div>
</section>
<section id="sigmoid">
<h5 id="sigmoid">Sigmoid<a class="headerlink" href="#sigmoid" title="Link to this heading">¶</a></h5>
<div class="math">
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Sigmoid</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>−</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{Sigmoid}(x) = \sigma(x) = \frac{1}{1 + \exp(-x)}

</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Sigmoid</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2574em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord">−</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div><img alt="https://pytorch.org/docs/stable/_images/Sigmoid.png" src="https://pytorch.org/docs/stable/_images/Sigmoid.png"/>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Sigmoid</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    逐元素，映射到0-1 ，靠近0变化大，否则变化缓慢</span>

<span class="sd">    Shape:</span>
<span class="sd">        都可以</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; m = nn.Sigmoid()</span>
<span class="sd">        &gt;&gt;&gt; input = torch.tensor([[-1., -1.],[2., 2.]])</span>
<span class="sd">        &gt;&gt;&gt; output = m(input)</span>
<span class="sd">        # output: tensor([[0.2689, 0.2689], [0.8808, 0.8808]])</span>
<span class="sd">    """</span>
    <span class="o">...</span>
</pre></div>
</div>
</section>
</section>
<section id="normalization">
<h4 id="normalization">Normalization<a class="headerlink" href="#normalization" title="Link to this heading">¶</a></h4>
</section>
<section id="droupout">
<h4 id="droupout">Droupout<a class="headerlink" href="#droupout" title="Link to this heading">¶</a></h4>
<div class="admonition-i-i-d-dropout admonition hint">
<p class="admonition-title">如果特征图中的相邻像素具有很强的相关性 (则 i.i.d. dropout 不会使激活正则化，否则只会导致有效学习率下降。</p>
</div>
<div class="admonition-batch admonition danger">
<p class="admonition-title">必须有batch！！！</p>
</div>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Dropout1d</span><span class="p">(</span><span class="n">_DropoutNd</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    随机取0，增强 feature maps 的独立性，防止过拟合。</span>
<span class="sd">    概率 p 伯努利采样</span>

<span class="sd">    Args:</span>
<span class="sd">        - p: Optional[Float]</span>
<span class="sd">        - inplace:bool</span>
<span class="sd">            default = False</span>

<span class="sd">    Shape:</span>
<span class="sd">        - Input: [B, C, L] 或 [C, L]</span>
<span class="sd">            卷积的时候：nn.Conv1d: 1D-tensor</span>
<span class="sd">        - Output: [B, C, L] 或 [C, L]</span>

<span class="sd">    Examples::</span>
<span class="sd">        &gt;&gt;&gt; m = nn.Dropout1d(p=0.2)</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(20, 16, 32)</span>
<span class="sd">        &gt;&gt;&gt; output = m(input)</span>
<span class="sd">    """</span>
    <span class="o">...</span>

<span class="k">class</span> <span class="nc">Dropout2d</span><span class="p">(</span><span class="n">_DropoutNd</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    随机取0，增强 feature maps 的独立性，防止过拟合。</span>
<span class="sd">    概率 p 伯努利采样</span>

<span class="sd">    Args:</span>
<span class="sd">        - p: Optional[Float]</span>
<span class="sd">        - inplace:bool</span>
<span class="sd">            default = False</span>

<span class="sd">    Shape:</span>
<span class="sd">        - Input: [B, C, H, W] 或 [B, C, L]</span>
<span class="sd">            卷积的时候：nn.Conv1d: 2D-tensor</span>
<span class="sd">        - Output: [B, C, H, W] 或 [B, C, L]</span>

<span class="sd">    Examples::</span>
<span class="sd">        &gt;&gt;&gt; m = nn.Dropout2d(p=0.2)</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(20, 16, 32, 32)</span>
<span class="sd">        &gt;&gt;&gt; output = m(input)</span>
<span class="sd">    """</span>
    <span class="o">...</span>
</pre></div>
</div>
</section>
<section id="flatten">
<h4 id="flatten"><cite>flatten</cite><a class="headerlink" href="#flatten" title="Link to this heading">¶</a></h4>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Flatten</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    给定维度展平向量</span>

<span class="sd">    Args:</span>
<span class="sd">        - start_dim: Int = 开始的维度</span>
<span class="sd">            default = 1</span>
<span class="sd">        - end_dim: Int  = 结束的维度</span>
<span class="sd">            default = -1</span>
<span class="sd">        default 就是 [B, H, W, ...] -&gt; [B, H*W*...], 最外层不会被展平</span>

<span class="sd">    Examples::</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(32, 1, 5, 5)</span>
<span class="hll"><span class="sd">        &gt;&gt;&gt; m = nn.Flatten() # 默认 0B 除外</span>
</span><span class="sd">        &gt;&gt;&gt; output = m(input)</span>
<span class="sd">        torch.Size([32, 25])</span>
<span class="hll"><span class="sd">        &gt;&gt;&gt; m = nn.Flatten(0, 2) # 自定义：最里面除外</span>
</span><span class="sd">        &gt;&gt;&gt; output = m(input)</span>
<span class="sd">        torch.Size([160, 5])</span>
<span class="sd">        &gt;&gt;&gt; m = nn.Flatten(0, -1) # 全展平</span>
<span class="sd">    """</span>
    <span class="o">...</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="torch-nn-loss-torch-optim">
<h2 id="torch-nn-loss-torch-optim"><code class="docutils literal notranslate"><span class="pre">torch.nn.</span></code> Loss &amp; <code class="docutils literal notranslate"><span class="pre">torch.Optim</span></code><a class="headerlink" href="#torch-nn-loss-torch-optim" title="Link to this heading">¶</a></h2>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="c1"># 定义模型</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="c1"># 定义 loss 算法</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="c1"># 定义 梯度迭代 的算法</span>
<span class="sd">""" basic """</span>
<span class="k">for</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="c1"># 算 loss</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span> <span class="c1"># 清空上一轮算出来的的梯度，否则梯度会累积</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># 通过 反向传播 计算新一轮梯度</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> <span class="c1"># 根据算出来的梯度 更新参数</span>
</pre></div>
</div>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">SGD</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
    <span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="sd">""" whole batch 整一个"""</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="n">loss_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loss_epoch</span> <span class="o">+=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>

    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss_epoch</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">loss_epoch</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="sd">""" mini-batch """</span>
</pre></div>
</div>
<section id="torch-optim">
<h3 id="torch-optim"><code class="docutils literal notranslate"><span class="pre">torch.optim</span></code><a class="headerlink" href="#torch-optim" title="Link to this heading">¶</a></h3>
<p>构建一个优化器对象，该对象将保持当前状态，并将根据计算的梯度更新参数。</p>
<div class="admonition-math-text-minimize-f-theta admonition danger">
<p class="admonition-title"><span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Minimize</mtext><mi>f</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Minimize} f(\theta)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Minimize</span></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span></span></p>
<p><code class="docutils literal notranslate"><span class="pre">maximize</span> <span class="pre">=</span> <span class="pre">False(default)</span></code> <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>  </mtext><mo>⟺</mo><mtext>  </mtext><msub><mi>g</mi><mi>t</mi></msub><mo>←</mo><mo>=</mo><mo>−</mo><mi mathvariant="normal">∇</mi><mi>f</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\iff g_t\leftarrow=-\nabla f(\theta)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.549em;vertical-align:-0.024em;"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">⟺</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">←=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span></span></p>
<div class="math">
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable columnalign="right left" columnspacing="0em" rowspacing="0.25em"><mtr><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow></mrow></mstyle></mtd><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow><mrow></mrow><mtext mathvariant="bold">关于梯度：</mtext><mi mathvariant="normal">∇</mi><mtext>是上升的方向</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow></mrow></mstyle></mtd><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow><mrow></mrow><mpadded height="0em" voffset="0em"><mspace height="0.04em" mathbackground="black" width="31.298em"></mspace></mpadded></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow></mrow></mstyle></mtd><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow><mrow></mrow><mtext mathvariant="bold">input</mtext><mo>:</mo><msub><mi>θ</mi><mn>0</mn></msub><mtext> (params)</mtext><mo separator="true">,</mo><mtext> </mtext><mi>f</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mtext> (objective)</mtext><mo separator="true">,</mo><mtext> </mtext><mtext mathvariant="italic">maximize</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow></mrow></mstyle></mtd><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow><mrow></mrow><mpadded height="0em" voffset="0em"><mspace height="0.04em" mathbackground="black" width="31.298em"></mspace></mpadded></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow></mrow></mstyle></mtd><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow><mrow></mrow><mspace width="1.4226em"></mspace><mtext mathvariant="bold">if</mtext><mtext> </mtext><mtext mathvariant="italic">maximize</mtext><mtext>  </mtext><mo>⟺</mo><mtext>  </mtext><mtext>Maximize </mtext><mi>f</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow></mrow></mstyle></mtd><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow><mrow></mrow><mspace width="2.8453em"></mspace><msub><mi>g</mi><mi>t</mi></msub><mo>←</mo><mo>+</mo><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi>f</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow></mrow></mstyle></mtd><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow><mrow></mrow><mspace width="1.4226em"></mspace><mtext mathvariant="bold">else</mtext><mtext>  </mtext><mo>⟺</mo><mtext>  </mtext><mtext>Minimize</mtext><mi>f</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow></mrow></mstyle></mtd><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow><mrow></mrow><mspace width="2.8453em"></mspace><msub><mi>g</mi><mi>t</mi></msub><mo>←</mo><mo>−</mo><msub><mi mathvariant="normal">∇</mi><mi>θ</mi></msub><mi>f</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow></mrow></mstyle></mtd><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow><mrow></mrow><mpadded height="0em" voffset="0em"><mspace height="0.04em" mathbackground="black" width="31.298em"></mspace></mpadded></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
&amp;\textbf{关于梯度：}\nabla 是上升的方向\\[-1em]
&amp;\rule{110mm}{0.4pt}\\
&amp;\textbf{input}:
    \theta_0 \text{ (params)}, \:
    f(\theta) \text{ (objective)}, \: \textit{maximize}\\[-1em]
&amp;\rule{110mm}{0.4pt}\\
&amp;\hspace{5mm}\textbf{if} \: \textit{maximize}\iff \text{Maximize }f(\theta)\\
&amp;\hspace{10mm}g_t \leftarrow  +\nabla_\theta f(\theta)\\
&amp;\hspace{5mm}\textbf{else}\iff \text{Minimize}f(\theta)\\
&amp;\hspace{10mm}g_t \leftarrow -\nabla_\theta f(\theta)\\[-1em]
&amp;\rule{110mm}{0.4pt}
\end{aligned}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:10.5em;vertical-align:-5em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.5em;"><span style="top:-7.5em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-7em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-5.5em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-5em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-3.5em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-2em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:-0.5em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:1em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span><span style="top:1.5em;"><span class="pstrut" style="height:2.84em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.5em;"><span style="top:-7.66em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord textbf cjk_fallback">关于梯度：</span></span><span class="mord">∇</span><span class="mord cjk_fallback">是上升的方向</span></span></span><span style="top:-7.16em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mord rule" style="border-right-width:31.298em;border-top-width:0.04em;bottom:0em;"></span></span></span><span style="top:-5.66em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord textbf">input</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord text"><span class="mord"> (params)</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mord text"><span class="mord"> (objective)</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord textit">maximize</span></span></span></span><span style="top:-5.16em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mord rule" style="border-right-width:31.298em;border-top-width:0.04em;bottom:0em;"></span></span></span><span style="top:-3.66em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226em;"></span><span class="mord text"><span class="mord textbf">if</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord text"><span class="mord textit">maximize</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">⟺</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord text"><span class="mord">Maximize </span></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span><span style="top:-2.16em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:2.8453em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">+</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span><span style="top:-0.66em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:1.4226em;"></span><span class="mord text"><span class="mord textbf">else</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">⟺</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord text"><span class="mord">Minimize</span></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span><span style="top:0.84em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:2.8453em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">−</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span><span style="top:1.34em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mord rule" style="border-right-width:31.298em;border-top-width:0.04em;bottom:0em;"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5em;"><span></span></span></span></span></span></span></span></span></span></span></span></div></div>
<div class="admonition-nesterov-momentum admonition note">
<p class="admonition-title">Nesterov momentum</p>
<div class="line-block">
<div class="line">is based on the formula from</div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">On</span> <span class="pre">the</span> <span class="pre">importance</span> <span class="pre">of</span> <span class="pre">initialization</span> <span class="pre">and</span> <span class="pre">momentum</span> <span class="pre">in</span> <span class="pre">deep</span> <span class="pre">learning</span></code></div>
</div>
</div>
<section id="adam">
<h4 id="adam">Adam<a class="headerlink" href="#adam" title="Link to this heading">¶</a></h4>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Adam</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Args:</span>
<span class="sd">        - params: iterable = 需要迭代的参数</span>
<span class="sd">        -  lr: Float &gt;0 = 学习率</span>
<span class="sd">            default = 1e-3</span>
<span class="sd">        - betas: Tuple(Float, Float)\in[0, 1)</span>
<span class="sd">            default = (0.9, 0.999)</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
                <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">foreach</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">maximize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">capturable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                <span class="n">differentiable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">fused</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="o">...</span>

    <span class="o">...</span>
</pre></div>
</div>
</section>
<section id="sgd">
<h4 id="sgd">SGD 随机梯度下降<a class="headerlink" href="#sgd" title="Link to this heading">¶</a></h4>
<p>SGD, Stochastic Gradient Descent(optionally with momentum)</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SGD</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    随机梯度下降</span>

<span class="sd">    Args:</span>
<span class="sd">        - params: iterable = 要迭代的参数</span>
<span class="sd">        - lr: Float &gt;0  = 学习率</span>
<span class="sd">        - momentum: Optional(Int) &gt;0 = 冲量</span>
<span class="sd">            default = 0</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">required</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dampening</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">nesterov</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">maximize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                <span class="n">foreach</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">differentiable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="o">...</span>

    <span class="o">...</span>
</pre></div>
</div>
</section>
<section id="adagrad">
<h4 id="adagrad">Adagrad, 自适应随机梯度下降<a class="headerlink" href="#adagrad" title="Link to this heading">¶</a></h4>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Adagrad</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Adaptive Stochastic Gradient</span>

<span class="sd">    Args:</span>
<span class="sd">        - params: iterable = 要迭代的参数</span>
<span class="sd">        - lr: Float &gt;0  = 学习率</span>
<span class="sd">            default = 1e-2</span>
<span class="sd">        - lr_decay: Float &gt;0</span>
<span class="sd">            default = 0</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">lr_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">initial_accumulator_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">eps</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">foreach</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span> <span class="n">maximize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span><span class="n">differentiable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,):</span>
        <span class="o">...</span>

    <span class="o">...</span>
</pre></div>
</div>
</section>
</section>
<section id="torch-nn-loss">
<h3 id="torch-nn-loss"><code class="docutils literal notranslate"><span class="pre">torch.nn.</span></code> Loss<a class="headerlink" href="#torch-nn-loss" title="Link to this heading">¶</a></h3>
<section id="l1loss-mae">
<h4 id="l1loss-mae">L1Loss, MAE<a class="headerlink" href="#l1loss-mae" title="Link to this heading">¶</a></h4>
<div class="math">
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>MAE</mtext><mo>=</mo><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable columnalign="left left" columnspacing="1em" rowspacing="0.36em"><mtr><mtd><mstyle displaystyle="false" scriptlevel="0"><mrow><mi mathvariant="double-struck">E</mi><mi mathvariant="normal">∣</mi><mover accent="true"><msub><mi>y</mi><mi>i</mi></msub><mo>^</mo></mover><mo>−</mo><msub><mi>y</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mo>∈</mo><mi mathvariant="double-struck">R</mi></mrow></mstyle></mtd><mtd><mstyle displaystyle="false" scriptlevel="0"><mtext>reduction=mean</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="false" scriptlevel="0"><mrow><mi mathvariant="normal">∥</mi><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>−</mo><mi>y</mi><msub><mi mathvariant="normal">∥</mi><mn>1</mn></msub><mo>∈</mo><mi mathvariant="double-struck">R</mi></mrow></mstyle></mtd><mtd><mstyle displaystyle="false" scriptlevel="0"><mtext>reduction=sum</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="false" scriptlevel="0"><mrow><mi mathvariant="normal">∣</mi><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>−</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>n</mi></msup></mrow></mstyle></mtd><mtd><mstyle displaystyle="false" scriptlevel="0"><mtext>reduction=none</mtext></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\text{MAE} = \ell(f)= \begin{cases}\mathbb{E}\vert\hat{y_i}-y_i\vert\in\R&amp;\text{reduction=mean} \\ \Vert\hat{y}-y\Vert_1\in\R&amp;\text{reduction=sum}\\\vert\hat{y}-y\vert\in\R^n&amp;\text{reduction=none}\end{cases}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord text"><span class="mord">MAE</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:4.32em;vertical-align:-1.91em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.35em;"><span style="top:-2.2em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎩</span></span></span><span style="top:-2.192em;"><span class="pstrut" style="height:3.15em;"></span><span style="height:0.316em;width:0.8889em;"><svg height="0.316em" preserveaspectratio="xMinYMin" style="width:0.8889em" viewbox="0 0 888.89 316" width="0.8889em" xmlns="http://www.w3.org/2000/svg"><path d="M384 0 H504 V316 H384z M384 0 H504 V316 H384z"></path></svg></span></span><span style="top:-3.15em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎨</span></span></span><span style="top:-4.292em;"><span class="pstrut" style="height:3.15em;"></span><span style="height:0.316em;width:0.8889em;"><svg height="0.316em" preserveaspectratio="xMinYMin" style="width:0.8889em" viewbox="0 0 888.89 316" width="0.8889em" xmlns="http://www.w3.org/2000/svg"><path d="M384 0 H504 V316 H384z M384 0 H504 V316 H384z"></path></svg></span></span><span style="top:-4.6em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎧</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.85em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.41em;"><span style="top:-4.41em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="mord">∣</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathbb">R</span></span></span><span style="top:-2.97em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord">∥</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathbb">R</span></span></span><span style="top:-1.53em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord">∣</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.91em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.41em;"><span style="top:-4.41em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">reduction=mean</span></span></span></span><span style="top:-2.97em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">reduction=sum</span></span></span></span><span style="top:-1.53em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">reduction=none</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.91em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div><div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">L1Loss</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    the mean absolute error (MAE)</span>

<span class="sd">    Args:</span>
<span class="sd">        - reduction: Optional[Str{'none', 'mean', 'sum}]</span>
<span class="sd">            default = 'mean'</span>

<span class="sd">    Examples::</span>
<span class="sd">        &gt;&gt;&gt; loss = nn.L1Loss()</span>
<span class="sd">        &gt;&gt;&gt; y = torch.randn(3, 5, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; pred = torch.randn(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; l = loss(pred, y) # 计算 loss</span>
<span class="sd">        &gt;&gt;&gt; output.backward() # 回溯</span>
<span class="sd">    """</span>
    <span class="o">...</span>
</pre></div>
</div>
</section>
<section id="mse">
<h4 id="mse">MSE<a class="headerlink" href="#mse" title="Link to this heading">¶</a></h4>
<div class="math">
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>MSE</mtext><mo>=</mo><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable columnalign="left left" columnspacing="1em" rowspacing="0.36em"><mtr><mtd><mstyle displaystyle="false" scriptlevel="0"><mrow><mi mathvariant="double-struck">E</mi><mo stretchy="false">(</mo><mover accent="true"><msub><mi>y</mi><mi>i</mi></msub><mo>^</mo></mover><mo>−</mo><msub><mi>y</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>∈</mo><mi mathvariant="double-struck">R</mi></mrow></mstyle></mtd><mtd><mstyle displaystyle="false" scriptlevel="0"><mtext>reduction=mean</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="false" scriptlevel="0"><mrow><mi mathvariant="normal">∥</mi><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>−</mo><mi>y</mi><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub><mo>∈</mo><mi mathvariant="double-struck">R</mi></mrow></mstyle></mtd><mtd><mstyle displaystyle="false" scriptlevel="0"><mtext>reduction=sum</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="false" scriptlevel="0"><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>−</mo><mi>y</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>n</mi></msup></mrow></mstyle></mtd><mtd><mstyle displaystyle="false" scriptlevel="0"><mtext>reduction=none</mtext></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\text{MSE} = \ell(f)= \begin{cases}\mathbb{E}(\hat{y_i}-y_i)^2\in\R&amp;\text{reduction=mean} \\ \Vert\hat{y}-y\Vert_2\in\R&amp;\text{reduction=sum}\\(\hat{y}-y)^2\in\R^n&amp;\text{reduction=none}
\end{cases}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord text"><span class="mord">MSE</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:4.32em;vertical-align:-1.91em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.35em;"><span style="top:-2.2em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎩</span></span></span><span style="top:-2.192em;"><span class="pstrut" style="height:3.15em;"></span><span style="height:0.316em;width:0.8889em;"><svg height="0.316em" preserveaspectratio="xMinYMin" style="width:0.8889em" viewbox="0 0 888.89 316" width="0.8889em" xmlns="http://www.w3.org/2000/svg"><path d="M384 0 H504 V316 H384z M384 0 H504 V316 H384z"></path></svg></span></span><span style="top:-3.15em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎨</span></span></span><span style="top:-4.292em;"><span class="pstrut" style="height:3.15em;"></span><span style="height:0.316em;width:0.8889em;"><svg height="0.316em" preserveaspectratio="xMinYMin" style="width:0.8889em" viewbox="0 0 888.89 316" width="0.8889em" xmlns="http://www.w3.org/2000/svg"><path d="M384 0 H504 V316 H384z M384 0 H504 V316 H384z"></path></svg></span></span><span style="top:-4.6em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎧</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.85em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.41em;"><span style="top:-4.41em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathbb">R</span></span></span><span style="top:-2.97em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord">∥</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathbb">R</span></span></span><span style="top:-1.53em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.91em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.41em;"><span style="top:-4.41em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">reduction=mean</span></span></span></span><span style="top:-2.97em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">reduction=sum</span></span></span></span><span style="top:-1.53em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">reduction=none</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.91em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div><div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MSELoss</span><span class="p">(</span><span class="n">_Loss</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    mean squared error (squared L2 norm)</span>

<span class="sd">    Args:</span>
<span class="sd">        - reduction: Optional[Str{'none', 'mean', 'sum}]</span>
<span class="sd">            default = 'mean'</span>

<span class="sd">    Examples::</span>
<span class="sd">        &gt;&gt;&gt; loss = nn.MSELoss()</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(3, 5, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.randn(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; output = loss(input, target)</span>
<span class="sd">        &gt;&gt;&gt; output.backward()</span>
<span class="sd">    """</span>
    <span class="o">...</span>
</pre></div>
</div>
</section>
<section id="celoss">
<h4 id="celoss">CELoss<a class="headerlink" href="#celoss" title="Link to this heading">¶</a></h4>
<div class="admonition-torch-nn-crossentropyloss admonition danger">
<p class="admonition-title"><code class="docutils literal notranslate"><span class="pre">torch.nn.CrossEntropyLoss()</span></code></p>
<div class="line-block">
<div class="line">= <code class="docutils literal notranslate"><span class="pre">torch.nn.LogSoftmax</span></code> + <code class="docutils literal notranslate"><span class="pre">torch.nn.NLLLoss</span></code></div>
<div class="line">softmax 非负化归一化 + 交叉熵</div>
</div>
</div>
<div class="math">
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtable columnalign="right left" columnspacing="0em" rowspacing="0.25em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow><mrow></mrow><mo>=</mo><msub><mi>w</mi><mi>y</mi></msub><mo>∗</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo stretchy="false">)</mo></mrow><mrow><munder><mo>∑</mo><mi>C</mi></munder><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo stretchy="false">)</mo></mrow></mfrac><mo>⋅</mo><mn mathvariant="double-struck">1</mn><mo stretchy="false">{</mo><msup><mi>y</mi><mo>∗</mo></msup><mo mathvariant="normal">≠</mo><mtext>ignore_index</mtext><mo stretchy="false">}</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow></mrow></mstyle></mtd><mtd><mstyle displaystyle="true" scriptlevel="0"><mrow><mrow></mrow><mo>=</mo><msub><mi>w</mi><msup><mi>y</mi><mo>∗</mo></msup></msub><mo>∗</mo><mo>−</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo stretchy="false">)</mo><mspace width="2em"></mspace><mtext> 不在忽略</mtext></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><mspace linebreak="newline"></mspace><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable columnalign="left left" columnspacing="1em" rowspacing="0.36em"><mtr><mtd><mstyle displaystyle="false" scriptlevel="0"><mrow><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mfrac><mn>1</mn><mrow><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msub><mi>w</mi><msub><mi>y</mi><mi>n</mi></msub></msub><mo>⋅</mo><mn mathvariant="double-struck">1</mn><mo stretchy="false">{</mo><msub><mi>y</mi><mi>n</mi></msub><mo>≠</mo><mtext>ignore_index</mtext><mo stretchy="false">}</mo></mrow></mfrac><msub><mi>l</mi><mi>n</mi></msub><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle displaystyle="false" scriptlevel="0"><mrow><mtext>if reduction</mtext><mo>=</mo><mtext>‘mean’;</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle displaystyle="false" scriptlevel="0"><mrow><msubsup><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msub><mi>l</mi><mi>n</mi></msub><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle displaystyle="false" scriptlevel="0"><mrow><mtext>if reduction</mtext><mo>=</mo><mtext>‘sum’.</mtext></mrow></mstyle></mtd></mtr></mtable></mrow><mspace linebreak="newline"></mspace><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>L</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>l</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>l</mi><mi>N</mi></msub><msup><mo stretchy="false">}</mo><mi mathvariant="normal">⊤</mi></msup><mo separator="true">,</mo><mspace width="1em"></mspace><msub><mi>l</mi><mi>n</mi></msub><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><msub><mi>w</mi><mi>c</mi></msub><mi>log</mi><mo>⁡</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>n</mi><mo separator="true">,</mo><mi>c</mi></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>n</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mfrac><msub><mi>y</mi><mrow><mi>n</mi><mo separator="true">,</mo><mi>c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\begin{align}\ell(f) &amp;=w_{y}  * - \log \cfrac{\exp(\hat{y})}{\sum_C \exp(\hat{y})}\cdot \mathbb{1}\{y^* \neq \text{ignore\_index}\}\\&amp;=w_{y^*}  * -\text{softmax}(\hat{y}) \qquad\text{ 不在忽略}\end{align}\\\ell(x, y)= \begin{cases}\sum_{n=1}^N \frac{1}{\sum_{n=1}^N w_{y_n} \cdot \mathbb{1}\{y_n \not= \text{ignore\_index}\}} l_n, &amp;\text{if reduction} = \text{`mean';}\\\sum_{n=1}^N l_n,  &amp;\text{if reduction} = \text{`sum'.}\end{cases}\\\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad l_n = - \sum_{c=1}^C w_c \log \frac{\exp(x_{n,c})}{\sum_{i=1}^C \exp(x_{n,i})} y_{n,c}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:4.3757em;vertical-align:-1.9379em;"></span><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.4379em;"><span style="top:-4.4379em;"><span class="pstrut" style="height:3.59em;"></span><span class="mord"><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mclose">)</span></span></span><span style="top:-2.3121em;"><span class="pstrut" style="height:3.59em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.9379em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.4379em;"><span style="top:-4.4379em;"><span class="pstrut" style="height:3.59em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1786em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.74em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">exp</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9857em;"><span></span></span></span></span></span><span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord"><span class="mrel"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord text"><span class="mord">ignore_index</span></span><span class="mclose">}</span></span></span><span style="top:-2.3121em;"><span class="pstrut" style="height:3.59em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2828em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">−</span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:2em;"></span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">不在忽略</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.9379em;"><span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.4379em;"><span style="top:-4.4379em;"><span class="pstrut" style="height:3.59em;"></span><span class="eqn-num"></span></span><span style="top:-2.3121em;"><span class="pstrut" style="height:3.59em;"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.9379em;"><span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1027em;vertical-align:-1.3013em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8013em;"><span style="top:-3.8013em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.5703em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8852em;"><span style="top:-2.1786em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-2.8971em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3214em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:-0.0269em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2306em;"><span style="top:-2.3em;margin-left:-0.0359em;margin-right:0.1em;"><span class="pstrut" style="height:2.5em;"></span><span class="mord mathnormal mtight">n</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2859em;"><span></span></span></span></span></span></span><span class="mbin mtight">⋅</span><span class="mord mtight">1</span><span class="mopen mtight">{</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord mtight"><span class="mrel mtight"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=</span><span class="mord text mtight"><span class="mord mtight">ignore_index</span></span><span class="mclose mtight">}</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6547em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span><span style="top:-2.1387em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3013em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8013em;"><span style="top:-3.8013em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">if reduction</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord text"><span class="mord">‘mean’;</span></span></span></span><span style="top:-2.1387em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">if reduction</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord text"><span class="mord">‘sum’.</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3013em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1491em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.1288em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">exp</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1709em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span></div><div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CrossEntropyLoss</span><span class="p">(</span><span class="n">_WeightedLoss</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    cross entropy loss, 二分类或多分类很有用，尤其是类别不平衡</span>

<span class="sd">    Warning:</span>
<span class="sd">        - 输入不必先经过 softmax（保证都为正且总和=1。</span>
<span class="sd">            因为这里会包括这个操作 = softmax-&gt;max-&gt;</span>

<span class="sd">    Shape</span>
<span class="sd">        - input: [C] 或 [B, C] 或  = 预测的，原始的不必经过 softmax</span>
<span class="sd">            C: #class</span>
<span class="sd">        - target: [1] 或 [B] = 真实的，类别，class indices</span>
<span class="sd">        - output:</span>
<span class="sd">            - 'none' : [1], [B]</span>
<span class="sd">            - 'mean', 'sum' : Int 或 [1]</span>

<span class="sd">    Args:</span>
<span class="sd">        - weight: optional(Tensor[C]) = 权</span>
<span class="sd">        - ignore_index: Optional[int] = 忽略的类别</span>
<span class="sd">            只有在 target 放的是正确的**类别(1, 2, ..)**才起效</span>
<span class="sd">            算 avg 时候 ignore 也 不算除数</span>
<span class="sd">        - reduction: Optional[Str{'none', 'mean', 'sum}]</span>
<span class="sd">            default = 'mean'</span>
<span class="sd">        - label_smoothing: Optional[Float] \in [0.0, 1.0].</span>
<span class="sd">            - default = 0.0 = no smoothing.</span>
<span class="sd">            看论文：`Rethinking the Inception Architecture for Computer Vision`</span>
<span class="sd">            a mixture of the original ground truth and a uniform distribution</span>

<span class="sd">    Examples::</span>
<span class="sd">        &gt;&gt;&gt; # Example of target with class indices</span>
<span class="sd">        &gt;&gt;&gt; loss = nn.CrossEntropyLoss()</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(3, 5, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.empty(3, dtype=torch.long).random_(5)</span>
<span class="sd">        # tensor([4, 3, 1])</span>
<span class="sd">        &gt;&gt;&gt; output = loss(input, target)</span>
<span class="sd">        -----------------------------------------------------------</span>
<span class="sd">        &gt;&gt;&gt; # Example of target with class probabilities</span>
<span class="sd">        &gt;&gt;&gt; input = torch.randn(3, 5, requires_grad=True)</span>
<span class="sd">        &gt;&gt;&gt; target = torch.randn(3, 5).softmax(dim=1)</span>
<span class="sd">        # tensor([[0.1190, 0.3896, 0.3429, 0.0254, 0.1231],</span>
<span class="sd">        #           [0.0963, 0.0300, 0.3308, 0.1970, 0.3459],</span>
<span class="sd">        #           [0.0920, 0.2793, 0.1674, 0.4453, 0.0159]])</span>
<span class="sd">        &gt;&gt;&gt; output = loss(input, target)</span>
<span class="sd">    """</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="save-load">
<h2 id="save-load">Save &amp; Load<a class="headerlink" href="#save-load" title="Link to this heading">¶</a></h2>
<div class="admonition-attributeerror-can-t-get-attribute-mymodel-on-module-main-from-xxx-py admonition danger">
<p class="admonition-title"><code class="docutils literal notranslate"><span class="pre">AttributeError:</span> <span class="pre">Can't</span> <span class="pre">get</span> <span class="pre">attribute</span> <span class="pre">'MyModel'</span> <span class="pre">on</span> <span class="pre">&lt;module</span> <span class="pre">'__main__'</span> <span class="pre">from</span> <span class="pre">'xxx.py'&gt;</span></code></p>
<p>自定义的模型 必须先import进来，否则就会加载不了</p>
</div>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">vgg16</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">vgg16</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
    <span class="o">...</span>
</pre></div>
</div>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="sd">"""</span>
<span class="sd">    :meth1: 整个模型保存</span>
<span class="sd">1. 内存较大</span>
<span class="sd">2. 在自设 architecture 的时候需要import</span>
<span class="sd">3. 如果里面有 GPU tensors, 就会自动上传到 GPU上</span>
<span class="sd">    To avoid GPU RAM surge</span>
<span class="sd">        first, torch.load(.., map_location='cpu')</span>
<span class="hll"><span class="sd">        then,  torch.load_state_dict(...)</span>
</span><span class="sd">"""</span>
<span class="hll">
</span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">vgg16</span><span class="p">,</span> <span class="s1">'./models/vgg16.pth'</span><span class="p">)</span> <span class="c1"># save</span>
<span class="n">vgg16</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'./models/vgg16.pth'</span><span class="p">)</span> <span class="c1"># load</span>
<span class="o">------------------------------------------</span>

<span class="n">mymodel</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">mymodel</span><span class="p">,</span> <span class="s1">'./models/mymodel.pth'</span><span class="p">)</span> <span class="c1"># save</span>

<span class="kn">from</span> <span class="nn">models</span> <span class="kn">import</span> <span class="n">MyModel</span> <span class="c1"># 加载的时候必须导入或者复制自定义的类 # load</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'./models/mymodel.pth'</span><span class="p">)</span>
<span class="hll">
</span><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'./models/mymodel.pth'</span><span class="p">))</span>
<span class="c1"># MyModel(</span>
<span class="hll"><span class="c1">#  (linear): Linear(in_features=4, out_features=2, bias=True)</span>
</span><span class="hll"><span class="c1">#  (sigmoid): Sigmoid())</span>
</span></pre></div>
</div>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="sd">"""</span>
<span class="sd">    :meth2: 以字典形式只保存参数</span>
<span class="sd">1. 内存较小，官方推荐</span>
<span class="sd">2. 加载时需要重新init model，然后把保存的参数传进去</span>
<span class="sd">"""</span>

<span class="n">vgg16</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">vgg16</span><span class="p">()</span>
<span class="hll"><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">vgg16</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'./models/vgg16_state.pth'</span><span class="p">)</span> <span class="c1"># save</span>
</span>
<span class="hll"><span class="n">vgg16</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">vgg16</span><span class="p">()</span>
</span><span class="hll"><span class="n">vgg16</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'./models/vgg16_state.pth'</span><span class="p">))</span> <span class="c1"># load</span>
</span>
<span class="n">mymodel</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
<span class="hll"><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">mymodel</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'./models/mymodel_state.pth'</span><span class="p">)</span>
</span>
<span class="hll"><span class="kn">from</span> <span class="nn">models</span> <span class="kn">import</span> <span class="n">MyModel</span>
</span><span class="hll"><span class="n">mymodel</span> <span class="o">=</span> <span class="n">Mymodel</span><span class="p">()</span>
</span><span class="hll"><span class="n">mymode</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="s1">'./models/mymodel_state.pth'</span><span class="p">)</span>
</span></pre></div>
</div>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'./mymodel_state.pth'</span><span class="p">))</span>
<span class="go">OrderedDict([</span>
<span class="go">    ('linear.weight', tensor([[ 0.1370, -0.0558, -0.0024, -0.2526],</span>
<span class="go">                              [-0.2042, -0.1686, -0.1526, -0.3912]])),</span>
<span class="go">    ('linear.bias', tensor([0.1713, 0.4829]))])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="go">MyModel(</span>
<span class="go">    (linear): Linear(in_features=4, out_features=2, bias=True)</span>
<span class="go">    (sigmoid): Sigmoid())</span>
</pre></div>
</div>
</section>
<section id="representation">
<h2 id="representation">representation<a class="headerlink" href="#representation" title="Link to this heading">¶</a></h2>
<section id="utils-tensorboard">
<h3 id="utils-tensorboard"><code class="docutils literal notranslate"><span class="pre">utils.tensorboard</span></code><a class="headerlink" href="#utils-tensorboard" title="Link to this heading">¶</a></h3>
<div class="admonition-tensorflow admonition danger">
<p class="admonition-title">目前还是要先下载 tensorflow</p>
<p><code class="docutils literal notranslate"><span class="pre">TensorFlow</span> <span class="pre">installation</span> <span class="pre">not</span> <span class="pre">found</span> <span class="pre">-</span> <span class="pre">running</span> <span class="pre">with</span> <span class="pre">reduced</span> <span class="pre">feature</span> <span class="pre">set.</span></code></p>
</div>
<div class="admonition-jupyter-tensorboard admonition danger">
<p class="admonition-title">jupyter 使用 tensorboard</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">load_ext</span> <span class="n">tensorboard</span> <span class="c1"># 加载扩展</span>
<span class="o">%</span><span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span> <span class="n">runs</span> <span class="c1"># 运行</span>
</pre></div>
</div>
<p>[在jupyter lab中使用tensorboard报错 UsageError: Line magic function <cite>%tensorboard</cite> not found.]</p>
</div>
<ul>
<li><p>SummaryWriter</p>
<blockquote>
<div><div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">()</span>
<span class="n">writer</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">'my_image'</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">'y=2x'</span><span class="p">,</span> <span class="n">i</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
<span class="n">writer</span> <span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p><span class="defi">source code</span></p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SummaryWriter</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    直接在 log_dir 里写 Tensorboard 要用的数据，可以在 training loop 里直接 call，而不用减缓训练的速度。</span>

<span class="sd">    Args:</span>
<span class="sd">        - log_dir: str = 存放的文件夹目录。</span>
<span class="sd">            Default = runs/**CURRENT_DATETIME_HOSTNAME**.</span>
<span class="sd">            Notes：对每次 experiment pass in 'runs/exp1', 'runs/exp2', etc.</span>
<span class="sd">        - comment: str = 只给默认的 log_dir 添加后缀</span>
<span class="sd">            Notes：log_dir 改了这个就没用</span>
<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; writer = SummaryWriter()</span>
<span class="sd">        # folder location: runs/May04_22-14-54_s-MacBook-Pro.local/</span>

<span class="sd">        &gt;&gt;&gt; # using the specified folder name.</span>
<span class="sd">        &gt;&gt;&gt; writer = SummaryWriter("my_experiment")</span>
<span class="sd">        # folder location: my_experiment</span>

<span class="sd">        &gt;&gt;&gt; # with comment appended.</span>
<span class="sd">        &gt;&gt;&gt; writer = SummaryWriter(comment="LR_0.1_BATCH_16")</span>
<span class="sd">        # folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_01_BATCH_16/</span>

<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">log_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">comment</span><span class="o">=</span><span class="s2">""</span><span class="p">,</span>
        <span class="n">purge_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">max_queue</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">flush_secs</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span>
        <span class="n">filename_suffix</span><span class="o">=</span><span class="s2">""</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">add_image</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span>
        <span class="n">img_tensor</span><span class="p">,</span>
        <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">dataformats</span><span class="o">=</span><span class="s2">"CHW"</span> <span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        写图片， 需要 ``pillow`` 包</span>

<span class="sd">        Args:</span>
<span class="sd">            - tag: str =  名字</span>
<span class="sd">            - img_tensor: Union[torch.Tensor, numpy.ndarray, string,blobname = Image data</span>
<span class="sd">            - dataformats: str = 格式：CHW, HWC, HW, WH, etc.</span>
<span class="sd">        """</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">add_scalar</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tag</span><span class="p">,</span>
        <span class="n">scalar_value</span><span class="p">,</span>
        <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">new_style</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">double_precision</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        画折线图</span>

<span class="sd">        Args:</span>
<span class="sd">            - tag: str = 名字</span>
<span class="sd">            - scalar_value: Optional[float or string/blobname] =  y 轴</span>
<span class="sd">            - global_step: int = x 轴，一般是 gloabl step 用作画迭代的变化</span>
<span class="sd">        """</span>
</pre></div>
</div>
</div></blockquote>
</li>
</ul>
<div class="admonition-no-dashboards-are-active-for-the-current-data-set admonition danger">
<p class="admonition-title"><code class="docutils literal notranslate"><span class="pre">No</span> <span class="pre">dashboards</span> <span class="pre">are</span> <span class="pre">active</span> <span class="pre">for</span> <span class="pre">the</span> <span class="pre">current</span> <span class="pre">data</span> <span class="pre">set.</span></code></p>
<p>[关于解决Tensorboard出现No dashboards are active for the current data set.问题]</p>
</div>
</section>
</section>
<section id="cv">
<h2 id="cv">CV<a class="headerlink" href="#cv" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>torchvion.</p></li>
</ul>
<section id="transforms">
<h3 id="transforms">transforms<a class="headerlink" href="#transforms" title="Link to this heading">¶</a></h3>
<div class="admonition-compose admonition danger">
<p class="admonition-title">一定要关注 compose 的输入和输出，要相互衔接匹配</p>
<p>torchvision 是用来处理 <span class="defi">图像</span> 的</p>
</div>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="hll"><span class="k">class</span> <span class="nc">Compose</span><span class="p">:</span>
</span><span class="w">    </span><span class="sd">"""</span>
<span class="sd">    用来 compose transform， 把好几个 trabsform process 组装成一个 composer</span>

<span class="sd">    Args:</span>
<span class="sd">        - transforms: List[transform的类]</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; trans = transforms.Compose([</span>
<span class="sd">        &gt;&gt;&gt;     transforms.CenterCrop(10),  # 中心切割</span>
<span class="sd">        &gt;&gt;&gt;     transforms.PILToTensor(), # 变成tensor</span>
<span class="sd">        &gt;&gt;&gt;     transforms.ConvertImageDtype(torch.float), # tensor dtyte</span>
<span class="sd">        &gt;&gt;&gt; ])</span>
<span class="sd">        &gt;&gt;&gt; img_trans = trans(img)</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transforms</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">is_scripting</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">is_tracing</span><span class="p">():</span>
            <span class="n">_log_api_usage_once</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">transforms</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        逐层去过</span>
<span class="sd">        """</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">t</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span>

    <span class="o">...</span>
<span class="hll"><span class="k">class</span> <span class="nc">ToTensor</span><span class="p">:</span>
</span><span class="w">    </span><span class="sd">"""</span>
<span class="sd">    转 PIL Image 或者 ndarray 变成 FloatTensor，并且 把值自动映射到01区间。</span>
<span class="sd">    (H x W x C) [0, 255] -&gt; (C x H x W)[0.0, 1.0]</span>
<span class="sd">    转 target/label 为 LongTensor</span>
<span class="sd">    用 PIL.Image.open(img_path)-&gt;PIL.image, cv2.imread(img_path)-&gt; numpy.ndarrary 都行</span>

<span class="sd">    - other cases: 不缩放</span>
<span class="sd">        - PIL Image 是其它 (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, -    - ndarray 是其它 (np.uint8)</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_log_api_usage_once</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pic</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">            - pic: Union[PIL Image, numpy.ndarray]</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor: torch.FloatTensor</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; img = Image.open(img_path)</span>
<span class="sd">            &gt;&gt;&gt; img2tensor = transforms.ToTensor()</span>
<span class="sd">            &gt;&gt;&gt; tensor_img = img2tensor(img)</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">pic</span><span class="p">)</span>
    <span class="o">...</span>
<span class="hll">
</span><span class="k">class</span> <span class="nc">Normalize</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    对 img Tensor 在每个 channel 正态标准化，默认 non-inplace</span>
<span class="sd">    ``output[channel] = (input[channel] - mean[channel]) / std[channel]``</span>

<span class="sd">    Args:</span>
<span class="sd">        - mean: sequence = Sequence of means for each channel.</span>
<span class="sd">        - std: sequence =  Sequence of standard deviations for each channel.</span>
<span class="sd">        - inplace: bool = False, 是否 inplace</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; trans_norm = transforms.Normalize([mean]*channel, [std]*channel)</span>
<span class="sd">        &gt;&gt;&gt; img_norm = trans_norm.forward(img_tensor)</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">_log_api_usage_once</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span> <span class="o">=</span> <span class="n">inplace</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">            - tensor: Tensor</span>

<span class="sd">        Returns:</span>
<span class="sd">            - Tensor: 归一化之后的 img</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span><span class="p">)</span>
    <span class="o">...</span>
<span class="hll">
</span><span class="k">class</span> <span class="nc">Resize</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Resize the input image to the given size.</span>

<span class="sd">    Warning:</span>
<span class="sd">        根据输入的不一样，在 downsampling 时 PIL Image 和 Tensor 的 interpolation 有不一样。</span>
<span class="sd">        ：建议：用同一个 input dtype 进行，不要混用</span>

<span class="sd">    Args:</span>
<span class="sd">        - size: Union[sequence, int]: = Optional[(h, w), size]</span>
<span class="sd">            - sequence = (h, w) 按位置匹配</span>
<span class="sd">            - int = size 短边变成size，长边按长短边的比例缩</span>
<span class="sd">                if h &gt; w , (h, w) = (size * h/w, size)</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; trans_resize = transforms.resize((heiht, width))</span>
<span class="sd">        &gt;&gt;&gt; img_resize = trans_resize(img)</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">InterpolationMode</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">,</span> <span class="n">max_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">antialias</span><span class="o">=</span><span class="s2">"warn"</span><span class="p">):</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">            - img: Optional[PIL Image, Tensor]</span>

<span class="sd">        Returns:</span>
<span class="sd">            Optional[PIL Image, Tensor]</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">interpolation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">antialias</span><span class="p">)</span>
    <span class="o">...</span>

<span class="hll">
</span>    <span class="k">class</span> <span class="nc">RandomCrop</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        随机裁剪</span>

<span class="sd">        Args:</span>
<span class="sd">            - size: Union[sequence, int]</span>
<span class="sd">                - sequence = (h, w) -&gt; (h, w)</span>
<span class="sd">                - int = size  -&gt; (size, size) 正方形裁剪</span>

<span class="sd">            - padding: Union[int, sequence, None] = 在各 border 上可选的 pad</span>
<span class="sd">                - None(default)</span>
<span class="sd">                - int = 四条边都填一样</span>
<span class="sd">                - sequence[int]*2 = [left&amp;right, top&amp;bottom]</span>
<span class="sd">                - sequence[int]*4 = [left, top, right, bottom] 顺时针</span>

<span class="sd">            - pad_if_needed: boolean = 为了避免裁剪完不合 expected size</span>
<span class="sd">        """</span>

        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pad_if_needed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s2">"constant"</span><span class="p">):</span>
            <span class="o">...</span>

        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
<span class="w">            </span><span class="sd">"""</span>
<span class="sd">            Args:</span>
<span class="sd">                - img:  Union[PIL.Image, Tensor]</span>

<span class="sd">            Returns:</span>
<span class="sd">                Union[PIL.Image, Tensor]</span>
<span class="sd">            """</span>
            <span class="o">...</span>
</pre></div>
</div>
</section>
<section id="models">
<h3 id="models">models<a class="headerlink" href="#models" title="Link to this heading">¶</a></h3>
<div class="admonition-defi-weights-pretrained-true admonition danger">
<p class="admonition-title">现在提供的是 可以自由地将 <span class="defi">预训练的 weights</span> 加载到模型上。（ <code class="docutils literal notranslate"><span class="pre">pretrained=True</span></code> 被舍用）</p>
<p>如果需要预训练的，推荐使用指定版本，因为还提供了每种权重对应的的图像预处理的操作。</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision.models</span> <span class="kn">import</span> <span class="n">resnet50</span><span class="p">,</span> <span class="n">ResNet50_Weights</span>

<span class="sd">"""</span>
<span class="sd">ver | accu    | name</span>
<span class="sd">Old | 76.130% | ResNet50_Weights.IMAGENET1K_V1</span>
<span class="sd">New | 80.858% | ResNet50_Weights.IMAGENET1K_V2</span>
<span class="sd">"""</span>

<span class="c1"># 直接看指定版本</span>
<span class="hll"><span class="n">resnet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">ResNet50_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
</span><span class="hll"><span class="n">resnet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">ResNet50_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V2</span><span class="p">)</span>
</span>
<span class="c1"># 字符串, 默认是哪个就得看文档</span>
<span class="n">resnet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">'IMAGENET1K_V2'</span><span class="p">)</span>
<span class="n">resnet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">'DEFAULT'</span><span class="p">)</span> <span class="c1"># = pretrained=True</span>
<span class="n">resnet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="c1"># = pretrained=False</span>
</pre></div>
</div>
</div>
<div class="admonition- admonition note">
<p class="admonition-title">预处理图像</p>
<div class="line-block">
<div class="line">在使用预训练模型之前，必须 ==预处理图像==（以正确的分辨率/插值调整大小，应用推理变换，重新缩放值等）</div>
<div class="line">现在统一提供了。</div>
</div>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">weights</span> <span class="o">=</span> <span class="n">ResNet50_Weights</span><span class="o">.</span><span class="n">DEFAULT</span>
<span class="n">preprocess</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">transforms</span><span class="p">()</span> <span class="c1"># Weight Transforms 初始化</span>
<span class="n">img_transformed</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="c1"># 预处理图像</span>
</pre></div>
</div>
</div>
<section id="vgg16">
<h4 id="vgg16">vgg16<a class="headerlink" href="#vgg16" title="Link to this heading">¶</a></h4>
<p>[Very Deep Convolutional Networks for Large-Scale Image Recognition]</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">VGG</span><span class="p">(</span>
<span class="p">(</span><span class="n">features</span><span class="p">):</span> <span class="n">Sequential</span><span class="p">(</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">6</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">7</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">9</span><span class="p">):</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">10</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">11</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">12</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">13</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">14</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">15</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">16</span><span class="p">):</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">17</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">18</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">19</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">20</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">21</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">22</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">23</span><span class="p">):</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">24</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">25</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">26</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">27</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">28</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">29</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">30</span><span class="p">):</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="p">)</span>
<span class="p">(</span><span class="n">avgpool</span><span class="p">):</span> <span class="n">AdaptiveAvgPool2d</span><span class="p">(</span><span class="n">output_size</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="p">(</span><span class="n">classifier</span><span class="p">):</span> <span class="n">Sequential</span><span class="p">(</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">25088</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">6</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="nd">@register_model</span><span class="p">()</span>
<span class="nd">@handle_legacy_interface</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="p">(</span><span class="s2">"pretrained"</span><span class="p">,</span> <span class="n">VGG16_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">vgg16</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">VGG16_Weights</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">progress</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">VGG</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    VGG-16</span>

<span class="sd">    Args:</span>
<span class="sd">        - weights: Optional(torchvision.models.VGG16_Weights, None) = 是否使用预训练的参数</span>
<span class="sd">            default = None</span>
<span class="sd">        - progress: Optional(Bool =  displays a progress bar of the download to stderr.</span>
<span class="sd">            default = True.</span>
<span class="sd">    """</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">VGG16_Weights</span><span class="o">.</span><span class="n">verify</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_vgg</span><span class="p">(</span><span class="s2">"D"</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">progress</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
<p>[关于解决Tensorboard出现No dashboards are active for the current data set.问题]: <a class="reference external" href="https://blog.csdn.net/qq_40128284/article/details/109343301">https://blog.csdn.net/qq_40128284/article/details/109343301</a>
[在jupyter lab中使用tensorboard报错 UsageError: Line magic function <cite>%tensorboard</cite> not found.]: <a class="reference external" href="https://blog.csdn.net/Casuall/article/details/109653238">https://blog.csdn.net/Casuall/article/details/109653238</a>
[Very Deep Convolutional Networks for Large-Scale Image Recognition]: <a class="reference external" href="https://arxiv.org/abs/1409.1556">https://arxiv.org/abs/1409.1556</a>
[【pytorch系列】 with torch.no_grad():用法详解]: <a class="reference external" href="https://blog.csdn.net/sazass/article/details/116668755">https://blog.csdn.net/sazass/article/details/116668755</a></p>
<p>[pytorch downlaod]: <a class="reference external" href="https://pytorch.org">https://pytorch.org</a>
[pytorch V.S.python]: <a class="reference external" href="https://github.com/pytorch/text/">https://github.com/pytorch/text/</a>
[pytorch V.S.cuda]:<a class="reference external" href="https://pytorch.org/get-started/previous-versions/">https://pytorch.org/get-started/previous-versions/</a></p>
</section>
</section>
</section>
</section>


          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
            <a href="numpy.html" title="Numpy &amp; Scipy"
               class="md-flex md-footer-nav__link md-footer-nav__link--prev"
               rel="prev">
              <div class="md-flex__cell md-flex__cell--shrink">
                <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
              </div>
              <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
                <span class="md-flex__ellipsis">
                  <span
                      class="md-footer-nav__direction"> "Previous" </span> Numpy &amp; Scipy </span>
              </div>
            </a>
          
          
            <a href="exam.html" title="笔面"
               class="md-flex md-footer-nav__link md-footer-nav__link--next"
               rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span
                class="md-flex__ellipsis"> <span
                class="md-footer-nav__direction"> "Next" </span> 笔面 </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink"><i
                class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2024, coconut.
              
          </div>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 7.3.7.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>