<!DOCTYPE html>

<html lang="zh-CN" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../../_static/javascripts/modernizr.js"></script>
  
  
  
    <title>CNN &#8212; cocobook  文档</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=83e35b93" />
    <link rel="stylesheet" type="text/css" href="../../_static/material.css?v=79c92029" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=87e54e7c" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/def.css?v=5a9d86bd" />
    <script src="../../_static/documentation_options.js?v=7d86a446"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/translations.js?v=beaddf03"></script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=blue-grey data-md-color-accent=blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#AI/DL/cnn" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../index.html" title="cocobook  文档"
           class="md-header-nav__button md-logo">
          
            &nbsp;
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">cocobook  文档</span>
          <span class="md-header-nav__topic"> CNN </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder=""Search""
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
      
  
  <script src="../../_static/javascripts/version_dropdown.js"></script>
  <script>
    var json_loc = "../../"versions.json"",
        target_loc = "../../../",
        text = "Versions";
    $( document ).ready( add_version_dropdown(json_loc, target_loc, text));
  </script>
  

    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
          <li class="md-tabs__item"><a href="../../index.html" class="md-tabs__link">cocobook  文档</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../index.html" title="cocobook 文档" class="md-nav__button md-logo">
      
        <img src="../../_static/" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../../index.html"
       title="cocobook 文档">cocobook  文档</a>
  </label>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">"Contents"</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#ai-dl-cnn--page-root" class="md-nav__link">CNN</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#introduction" class="md-nav__link">Introduction</a>
        </li>
        <li class="md-nav__item"><a href="#keywords" class="md-nav__link">Keywords</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#shared-weights" class="md-nav__link">Shared Weights，共享权重</a>
        </li>
        <li class="md-nav__item"><a href="#local-receptive-fields-sparse-connectivity" class="md-nav__link">Local Receptive Fields & Sparse Connectivity, 局部感知域 & 稀疏连接</a>
        </li>
        <li class="md-nav__item"><a href="#spatial-information" class="md-nav__link">Spatial Information</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#structure" class="md-nav__link">Structure</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#input-layer" class="md-nav__link">Input Layer</a>
        </li>
        <li class="md-nav__item"><a href="#convolution-layers-conv" class="md-nav__link">Convolution Layers, Conv</a>
        </li>
        <li class="md-nav__item"><a href="#filters-kernels" class="md-nav__link">Filters, Kernels</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#about-size" class="md-nav__link">about Size</a>
        </li>
        <li class="md-nav__item"><a href="#about-stride-s" class="md-nav__link">about Stride s：移动的方格</a>
        </li>
        <li class="md-nav__item"><a href="#about-padding" class="md-nav__link">about Padding</a>
        </li>
        <li class="md-nav__item"><a href="#about-meaning" class="md-nav__link">about Meaning</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#batch-normalization" class="md-nav__link">Batch Normalization</a>
        </li>
        <li class="md-nav__item"><a href="#activation-function" class="md-nav__link">Activation function</a>
        </li>
        <li class="md-nav__item"><a href="#pooling-layer" class="md-nav__link">Pooling Layer, 池化层</a>
        </li>
        <li class="md-nav__item"><a href="#flatten-layer-tensor-reshape" class="md-nav__link">Flatten Layer — Tensor Reshape</a>
        </li>
        <li class="md-nav__item"><a href="#fully-connected-layer-fc" class="md-nav__link">Fully- Connected Layer, FC</a>
        </li>
        <li class="md-nav__item"><a href="#softmax" class="md-nav__link">softmax</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#famous-cnn-architectures" class="md-nav__link">Famous CNN Architectures</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#deeper-or-wider" class="md-nav__link">Deeper or Wider?</a>
        </li>
        <li class="md-nav__item"><a href="#lenet-5" class="md-nav__link"><strong>LeNet-5</strong></a>
        </li>
        <li class="md-nav__item"><a href="#alexnet" class="md-nav__link">AlexNet</a>
        </li>
        <li class="md-nav__item"><a href="#vgg-net" class="md-nav__link">VGG Net</a>
        </li>
        <li class="md-nav__item"><a href="#residual-net-resnet" class="md-nav__link">Residual Net, <strong>ResNet</strong></a>
        </li>
        <li class="md-nav__item"><a href="#dense-net" class="md-nav__link"><strong>Dense Net</strong></a>
        </li>
        <li class="md-nav__item"><a href="#googlenet" class="md-nav__link"><strong>GoogleNet</strong></a>
        </li>
        <li class="md-nav__item"><a href="#light-weight-networks" class="md-nav__link">Light-weight networks</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#practical-exercise" class="md-nav__link">Practical Exercise</a>
        </li>
        <li class="md-nav__item"><a href="#parameters-initialization" class="md-nav__link">Parameters Initialization</a>
        </li>
        <li class="md-nav__item"><a href="#bach-normalization" class="md-nav__link">Bach Normalization</a>
        </li>
        <li class="md-nav__item"><a href="#application" class="md-nav__link">Application</a>
        </li>
        <li class="md-nav__item"><a href="#edge-detection" class="md-nav__link">Edge Detection</a>
        </li>
        <li class="md-nav__item"><a href="#exercise" class="md-nav__link">Exercise</a>
        </li>
        <li class="md-nav__item"><a href="#code" class="md-nav__link">code</a>
        </li></ul>
            </nav>
        </li>
    
<li class="md-nav__item"><a class="md-nav__extra_link" href="../../_sources/AI/DL/cnn.rst.txt">显示源代码</a> </li>

<li id="searchbox" class="md-nav__item"></li>

  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <section id="cnn">
<h1 id="ai-dl-cnn--page-root">CNN<a class="headerlink" href="#ai-dl-cnn--page-root" title="Link to this heading">¶</a></h1>
<p>!!! danger “To maintain spatial struture.”</p>
<dl>
<dt>!!! p “summary”</dt><dd><p><span class="defi">Conv</span></p>
<ul class="simple">
<li><p>Accept a volume of size $W_1times H_1times D_1$</p></li>
<li><p>Requires 4 hyperparameters
- Number of filters $K$
- Filter’ size $F$
- Stride $S$
- Zero padding $P$</p></li>
<li><p>Number of weights $(Ftimes Ftimes D_1)times K + Ktext{(shared bias)}$</p></li>
<li><p>Produce a volume of size $(frac{W_1-F+2P}{S}+1)times(frac{H_1-F+2P}{S}+1)times K$</p></li>
<li><p>In the output volume, the $d^{th}$ of $W_2times H_2$ is the result of performing a valid convolution of the $d^{th}$ filter over the input volume with a stride $S$, and the offser by $d^{th}$ bias.</p></li>
</ul>
<aside class="system-message">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 18)</p>
<p>Bullet list ends without a blank line; unexpected unindent.</p>
</aside>
<p>—</p>
<p><span class="defi">Pool</span></p>
<ul class="simple">
<li><p>Accept a volume of size $W_2times H_2times K$</p></li>
<li><p>Requires 2 hyperparameters
- pooling kernel’ size $F$
- Stride $S$</p></li>
<li><p>Number of weights $0$</p></li>
<li><p>Produce a volume of size $(frac{W_2-F}{S}+1)times(frac{H_2-F}{S}+1)$</p></li>
<li><p>It is not common to use zero padding for pooling layer.</p></li>
</ul>
</dd>
<dt>!!! p “common setting”</dt><dd><p>$K$ 2 的幂
F3S1P1, F5S1P2, F5S2P(whatever fits),F1S1P0</p>
</dd>
</dl>
<section id="introduction">
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Link to this heading">¶</a></h2>
<p><strong>In：</strong> Vision Task，就是**针对图像这一特殊结构**，包括图片分类, Object Detection 目标检测，边缘检测, Object Segmentation 目标提取，图片风格迁移， Image Captioning 看图说话, Retrieval 恢复图片…</p>
<p>关于处理的图片对象，有单纯基于 <strong>黑白照片灰度图像(width✖️height)</strong> 的卷积，也有基于 <strong>彩色照片立体RGB(wideth✖️height✖️depthchannel)</strong> 的卷积</p>
<dl class="simple">
<dt>!!! p “”</dt><dd><p>&lt;u&gt;CNN is a sequence of Convolution Layers, interspersed with activation functions&lt;/u&gt;.
&lt;div class=”grid” markdown&gt;
&lt;p&gt;CNN is proposed to reduce the number of parameters, preserve the image layout information, and make the network deeper &lt;/p&gt;
&lt;figure markdown=”span”&gt;![](./pics/CNN_22.png){width=80%}&lt;/figure&gt;
&lt;/div&gt;</p>
</dd>
</dl>
<p>!!! p “和全连接相比较，全连接的参数数量较多（两层之间的神经元需要两两相连），卷积神经网络的参数较少，主要是由于权值共享和稀疏连接。”</p>
<p>![](./pics/CNN_1.png){width=80%}
![](./pics/CNN_2.png){width=80%}
![](./pics/CNN_3.png){width=80%}
![](./pics/CNN_4.png){width=80%}</p>
<ol class="arabic simple">
<li><p>The input of image data into the convolution neural network is processed with the help of pixel values of the image in the convolution layer.</p></li>
<li><p><span class="defi">Filters</span> are generated that perform convolutions over the entire image and train the network to identify and learn features from images, which are converted to matrices.</p></li>
<li><p><span class="defi">Batch</span> normalization of input vectors is performed at each layer, so as to ensure all input vectors are <strong>normalized</strong> and hence regularization in the network is attained.</p></li>
<li><p>The convolutions are performed until better accuracy has been attained and maximum feature extraction is done.</p></li>
<li><p>Convolutions result in the <strong>sub-sampling</strong> of images and the dimensions of input get changed according to <span class="defi">padding</span> and <span class="defi">stride</span> chosen.</p></li>
<li><p>Each convolution follows the <span class="defi">activation layer(ReLU)</span> and ==pooling layer==, which brings in <strong>non-linearity</strong> and helps in <strong>sub-sampling</strong> respectively.</p></li>
<li><p>After the final convolution, the input matrix is converted to feature vectors. This feature vector is the ==flattened layer==.</p></li>
<li><p>Feature vector serves as input to the next layer(fully connected layer), where all features are collectively transferred into this network. <span class="defi">Dropout</span> of random nodes occurs during training to reduce overfitting in this layer.</p></li>
<li><p>Finally, the raw values which are predicted output by the network are converted to probabilistic values with the use of ==softmax function==.</p></li>
</ol>
</section>
<section id="keywords">
<h2 id="keywords">Keywords<a class="headerlink" href="#keywords" title="Link to this heading">¶</a></h2>
<p>==共享权重==, ==局部感知域 &amp; 稀疏连接==,:defi:<cite>Spatial Information</cite></p>
<section id="shared-weights">
<h3 id="shared-weights">Shared Weights，共享权重<a class="headerlink" href="#shared-weights" title="Link to this heading">¶</a></h3>
<p>同一个filter在输入矩阵中进行扫描</p>
<p>一个隐藏层中的所有**神经元都检测在图像的不同位置处的同一个特征。权重共享，则检测特征相同。** 因此也将从输入层到隐藏层的这种映射称为&lt;u&gt;特征映射，filters, kernels&lt;/u&gt;。该特征映射的权重称为**共享权重**，其偏置称为共享偏置。</p>
</section>
<section id="local-receptive-fields-sparse-connectivity">
<h3 id="local-receptive-fields-sparse-connectivity">Local Receptive Fields &amp; Sparse Connectivity, 局部感知域 &amp; 稀疏连接<a class="headerlink" href="#local-receptive-fields-sparse-connectivity" title="Link to this heading">¶</a></h3>
<p>For convolution with kernel size $K$, each element in the output depends on a $Ktimes K$ receptive field in the input.
Each successive convolution contains multiple regions from the previous one.
输出矩阵中的每一个数值只由输入数据的一部分计算得来。与常规神经网络一样，输入层的神经元需要和隐藏层的神经元连接。但这里**不是将每一个输入神经元都与每一个隐藏神经元连接**，而是仅仅在一个图像的**局部区域创建连接**</p>
<p>![](./pics/CNN_5.png){width=60%}
![](./pics/CNN_6.png){width=60%}</p>
</section>
<section id="spatial-information">
<h3 id="spatial-information">Spatial Information<a class="headerlink" href="#spatial-information" title="Link to this heading">¶</a></h3>
<p>输入层：<strong>二维矩阵排列**的**神经元</strong>。</p>
</section>
</section>
<section id="structure">
<h2 id="structure">Structure<a class="headerlink" href="#structure" title="Link to this heading">¶</a></h2>
<p>![](./pics/CNN_21.png){width=80%}</p>
<section id="input-layer">
<h3 id="input-layer">Input Layer<a class="headerlink" href="#input-layer" title="Link to this heading">¶</a></h3>
<p><strong>二维矩阵排列**的**神经元</strong>。</p>
</section>
<section id="convolution-layers-conv">
<h3 id="convolution-layers-conv">Convolution Layers, Conv<a class="headerlink" href="#convolution-layers-conv" title="Link to this heading">¶</a></h3>
<p>!!! p “Convolve the filter with the image $Rightarrow$ &lt;u&gt;slide over the image spatially, computing dot products&lt;/u&gt;”</p>
<p>完成图像和filter 的卷积就是</p>
<ol class="arabic">
<li><p>用一个小小的 $Ftimes Ftimes D$ shared filter 在$Ntimes Ntimes D$ 图像上 slide spatially, 空间意义上地滑动。</p></li>
<li><p>滑动的时候，每一次框定的**小小对应尺寸** $Ftimes Ftimes D$ 块 chunk of the image, Local Receptive Fields，和 $Ftimes Ftimes D$ shared filter 做 dot product ==element-wise multiplication==，.</p>
<blockquote>
<div><dl class="simple">
<dt>!!! danger “”</dt><dd><p>D个 channel，都要分别和输入的D个channel 做卷积，得到D个特征图，然后**通道融合, sum all the (weights x inputs) of D channels**</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p>将所有滑动的到的结果按空间顺序重新拼成: $(N-F+1)times(N-F+1)times red{1}$ tensor</p></li>
<li><p>再加上 $(N-F+1)times(N-F+1)times red{1}$ shared bias 偏置</p></li>
</ol>
<p>以上是做一个filter的过程。$w^Tx+b$。
因为 input image 和 filter 的乘法是 ==element-wise multiplication==，就和向量点积一样，所以可以想象为多维的 chunk 和 filter 和 bias 展平成向量，$R^{Ftimes Ftimes D}xrightarrow{text{Flatten}}R^{F^2Dtimes 1}xrightarrow{text{dot product}}R$</p>
<p>$K$ 个 filters 就有 $K$ 个 tensor，最后 <strong>stack 堆叠</strong> these up to get a new “image tensor”<span class="defi">activation map</span> of size as the input of the next layer. 立体卷积的输出结果的维度，长和宽和之前灰度图像的计算一样，而**结果的通道数则由过滤器的个数决定**
$$(N-F+1)times(N-F+1)times red{K}$$</p>
<p>&lt;div class=”grid” markdown&gt;
&lt;figure markdown=”span”&gt;![](./pics/CNN_7.jpeg){width=90%}&lt;p&gt;平面的，e.g.：<a href="#id1"><span class="problematic" id="id2">**</span></a>黑白照片灰度图像**&lt;/p&gt;&lt;/figure&gt;
&lt;figure markdown=”span”&gt;![](./pics/CNN_8.png)&lt;p&gt;立体的，e.g：<a href="#id3"><span class="problematic" id="id4">**</span></a>彩色照片立体RGB图像**&lt;/p&gt;&lt;/figure&gt;
&lt;/div&gt;</p>
<aside class="system-message" id="id1">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 124); <em><a href="#id2">backlink</a></em></p>
<p>Inline strong start-string without end-string.</p>
</aside>
<aside class="system-message" id="id3">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 124); <em><a href="#id4">backlink</a></em></p>
<p>Inline strong start-string without end-string.</p>
</aside>
<ul class="simple">
<li><p>立体的，e.g：<strong>彩色照片立体RGB图像</strong></p></li>
</ul>
<aside class="system-message">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 130)</p>
<p>Bullet list ends without a blank line; unexpected unindent.</p>
</aside>
<p>过滤器是一个立方体，在输入数据上扫描，每一个通道的权重分别与输入图片的每一个通道扫描到的值相乘再加和得到输出矩阵上的一个输出值</p>
<p>&lt;figure markdown=”span”&gt;![](./pics/CNN_9.png){width=90%}&lt;p&gt;立体的，e.g：<a href="#id5"><span class="problematic" id="id6">**</span></a>彩色照片立体RGB图像**&lt;/p&gt;&lt;/figure&gt;</p>
<aside class="system-message" id="id5">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 132); <em><a href="#id6">backlink</a></em></p>
<p>Inline strong start-string without end-string.</p>
</aside>
<p>&lt;figure markdown=”span”&gt;![](./pics/CNN_10.png){width=90%}&lt;p&gt;立体的，e.g：<a href="#id7"><span class="problematic" id="id8">**</span></a>彩色照片立体RGB图像**&lt;/p&gt;&lt;/figure&gt;</p>
<aside class="system-message" id="id7">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 134); <em><a href="#id8">backlink</a></em></p>
<p>Inline strong start-string without end-string.</p>
</aside>
</section>
<section id="filters-kernels">
<h3 id="filters-kernels">Filters, Kernels<a class="headerlink" href="#filters-kernels" title="Link to this heading">¶</a></h3>
<p>!!! p “Input Image x  Feature Detector = ==Feature Map==”</p>
<section id="about-size">
<h4 id="about-size">about Size<a class="headerlink" href="#about-size" title="Link to this heading">¶</a></h4>
<ol class="arabic">
<li><dl>
<dt>always <a href="#id9"><span class="problematic" id="id10">**</span></a>extend the full depth o**f the input volume， 一个 filter 的深度(通道数)要和 input 的深度(通道数)一样，但是输出仍只有一个通道数。</dt><dd><aside class="system-message" id="id9">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 144); <em><a href="#id10">backlink</a></em></p>
<p>Inline strong start-string without end-string.</p>
</aside>
<p>$$18=cfrac{32-5}{1}+1, 30=cfrac{32-3}{1}+1$$</p>
<p><code class="docutils literal notranslate"><span class="pre">`mermaid</span>
<span class="pre">graph</span> <span class="pre">LR</span>
<span class="pre">A[Input&lt;br&gt;32✖️32✖️&lt;FONT</span> <span class="pre">COLOR="#ff0000"&gt;3&lt;/FONT&gt;]</span>
<span class="pre">B{Filter&lt;br&gt;5✖️5✖️&lt;FONT</span> <span class="pre">COLOR="#ff0000"&gt;3&lt;/FONT&gt;}</span>
<span class="pre">C{Filter&lt;br&gt;3✖️3✖️&lt;FONT</span> <span class="pre">COLOR="#ff0000"&gt;3&lt;/FONT&gt;}</span>
<span class="pre">A</span> <span class="pre">--&gt;</span> <span class="pre">B</span>
<span class="pre">A</span> <span class="pre">--&gt;</span> <span class="pre">C</span>
<span class="pre">D{Stride&lt;br&gt;1}</span>
<span class="pre">B</span> <span class="pre">---</span> <span class="pre">D</span>
<span class="pre">C</span> <span class="pre">---</span> <span class="pre">D</span>
<span class="pre">E[Output&lt;br&gt;18✖️18✖️&lt;FONT</span> <span class="pre">COLOR="#ff0000"&gt;1&lt;/FONT&gt;]</span>
<span class="pre">F[Output&lt;br&gt;30✖️30✖️&lt;FONT</span> <span class="pre">COLOR="#ff0000"&gt;1&lt;/FONT&gt;]</span>
<span class="pre">D</span> <span class="pre">--&gt;</span> <span class="pre">E</span>
<span class="pre">D</span> <span class="pre">--&gt;</span> <span class="pre">F</span>
<span class="pre">`</span></code></p>
<p>![](./pics/CNN_11.png){width=60%}</p>
</dd>
</dl>
</li>
<li><p>dim of <strong>filter 一般为奇数，若为偶数，则会产生不对称填充</strong></p></li>
</ol>
<aside class="system-message">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 166)</p>
<p>Enumerated list ends without a blank line; unexpected unindent.</p>
</aside>
<p>3. <strong>1✖️1 Convolution</strong> is meaningful!
It computes the dot product over the channels.</p>
<p>&lt;figure markdown=”span”&gt;![](./pics/CNN_13.png){width=60%}&lt;p&gt;1✖️1 Convolution&lt;/p&gt;&lt;/figure&gt;</p>
<p><strong>advantages：</strong></p>
<ul>
<li><p>Shrinking too volumes spatially</p>
<blockquote>
<div><p>!!! danger “Shrinking too fast is not good,”</p>
</div></blockquote>
</li>
</ul>
<p>比如说CNN，CNN是用卷积核和感受野做运算，每一个新产生特征数，也就是 output 的一个小小的数字，囊括的也只是一个小小的感受野的信息。对一个kernel 来说，虽然 output 是由所有的感受野 of input 卷积之后堆叠而成的一个 [L, W]矩阵，也就是这一个 kernel 和所有的感受野做运算的结果堆叠而成。但是 <strong>简单局部特征堆叠不等于全局特征。</strong> 这也是CNN稀疏链接的特点。</p>
<p>所以我们常说CNN对于那种长序列 long sequence input 不太友好，因为对于两个间隔比较远的 pixels 来说，要是想获得他们之间的关系特征，就需要堆叠很多个卷积层，才能获得他们的关系特征。</p>
<p>![](./pics/CNN_25.jpeg){width=60%}</p>
</section>
<section id="about-stride-s">
<h4 id="about-stride-s">about Stride s：移动的方格<a class="headerlink" href="#about-stride-s" title="Link to this heading">¶</a></h4>
<ol class="arabic">
<li><p>s = 1 （default）</p></li>
<li><p><strong>do not want to capture all the data</strong> or information available so we skip some.</p></li>
<li><p>设置的 stride 要被刚好设置的filter卷积到$$red{text{Output Size }(cfrac{N-F}{s}+1)times(cfrac{N-F}{s}+1) }, quadcfrac{N-F}{text{stride}}in Z $$</p>
<blockquote>
<div><p>![](./pics/CNN_12.png){width=40%}</p>
</div></blockquote>
</li>
</ol>
<p><strong>drawbacks：</strong></p>
<ul class="simple">
<li><p>lose data over borders 容易丢失边缘或者是角落上的像素信息，譬如所当 stride=1 的时候，边边就出现一遍，中间的部分会在滑动的时候overlap 到，出现次数就会重复，这也体现了一种设定：图像中间总是比较重要，承载更多信息</p></li>
</ul>
<p><strong>advantages：</strong></p>
<ol class="arabic simple">
<li><p>输出的图片会缩小</p></li>
</ol>
</section>
<section id="about-padding">
<h4 id="about-padding">about Padding<a class="headerlink" href="#about-padding" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>为什么要pad？</p></li>
</ul>
<aside class="system-message">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 204)</p>
<p>Bullet list ends without a blank line; unexpected unindent.</p>
</aside>
<p>为了解决容易丢失边缘或者是角落上的像素信息。pad之后本来边缘的部分就不会只出现一次。 $impliedby$&lt;u&gt;convolved 之前 pad&lt;/u&gt;. Due to padding, information on the borders of images is also preserved similarly to at the centre of images.
- 在哪里pad？ pad 的范围多大</p>
<aside class="system-message">
<p class="system-message-title">System Message: ERROR/3 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 206)</p>
<p>Unexpected indentation.</p>
</aside>
<blockquote>
<div><ul class="simple">
<li><p>To 解决边缘容易丢失 $implies$ &lt;u&gt;on the boundary&lt;/u&gt;, image 的四周都要 pad. 范围自定义, <strong>pad with p-pixel border</strong></p></li>
<li><p>To <strong>卷积前后大小不变</strong>，==$p=cfrac{F-1}{2}:text{when s=1}$==</p></li>
</ul>
<aside class="system-message">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 208)</p>
<p>Bullet list ends without a blank line; unexpected unindent.</p>
</aside>
<p>$p=cfrac{N(s-1)+F-s}{2}$</p>
</div></blockquote>
<p><strong>保证卷积前后的维度不变，</strong></p>
<ul>
<li><p>proof of  formula of p <strong>此处stride=1（default）</strong></p>
<blockquote>
<div><p>$N= N+2p-F+1implies p=cfrac{F-1}{2}$</p>
</div></blockquote>
</li>
<li><p>pad 什么？</p></li>
</ul>
<aside class="system-message">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 216)</p>
<p>Bullet list ends without a blank line; unexpected unindent.</p>
</aside>
<p>&lt;u&gt;pad 0&lt;/u&gt; on the boundary，因为做的是 dot product，不会影响结果</p>
<p>$$begin{align*}
text{Output Size without padding}&amp;=(cfrac{N-F}{s}+1)times(cfrac{N-F}{s}+1)\
text{Output Size with padding}&amp;=(cfrac{N+2p-F}{s}+1)times(cfrac{N+2p-F}{s}+1)
end{align*}$$</p>
<p>![](./pics/CNN_16.png){width=60%}</p>
</section>
<section id="about-meaning">
<h4 id="about-meaning">about Meaning<a class="headerlink" href="#about-meaning" title="Link to this heading">¶</a></h4>
<ol class="arabic simple">
<li><p>同一张特征图，同一个通道，上的所有元素 (神经元) 都是对图像的不同位置的同一个特征的检测，通道中某一处 (特征图上某一个神经元) 数值的大小就是当前位置对当前特征强弱的反应。</p></li>
</ol>
<aside class="system-message">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 229)</p>
<p>Enumerated list ends without a blank line; unexpected unindent.</p>
</aside>
<p>2. 一个 filter 就是一个特征，每个 filter 体现的特质都不一样。
为了使得模型将注意力集中于图片的某些位置，<strong>而在深度学习中，更好的方法是将过滤器里面的值设置成参数，让模型通过反向传播去学习到过滤器中的权重值</strong>，代替人为的设定。</p>
<p>&lt;div class=”grid” markdown&gt;
&lt;figure markdown=”span”&gt;![](./pics/CNN_14.png)&lt;p&gt;yellow&lt;/p&gt;&lt;/figure&gt;
&lt;figure markdown=”span”&gt;![](./pics/CNN_15.png)&lt;p&gt;roll&lt;/p&gt;&lt;/figure&gt;
&lt;/div&gt;</p>
<ol class="arabic simple">
<li><p>&lt;u&gt;立体的 filter&lt;/u&gt;，每一个通道的权重分别对应输入图片的每一个通道。<strong>可以通过设置过滤器不同通道的权值来关注于原始图片不同通道的内容</strong></p></li>
</ol>
</section>
</section>
<section id="batch-normalization">
<h3 id="batch-normalization">Batch Normalization<a class="headerlink" href="#batch-normalization" title="Link to this heading">¶</a></h3>
<p>Batch normalization is generally done in between convolution and activation(ReLU) layers. It normalizes the inputs at each layer, reduces internal co-variate shift(change in the distribution of network activations) and is a method to regularize a convolutional network.</p>
<p>Batch normalizing allows higher learning rates that can reduce training time and gives better performance. It allows learning at each layer by itself without being more dependent on other layers. Dropout which is also a regularizing technique, is less effective to regularize convolution layers.</p>
</section>
<section id="activation-function">
<h3 id="activation-function">Activation function<a class="headerlink" href="#activation-function" title="Link to this heading">¶</a></h3>
<p>卷积操作只是加权求和的线性操作，若神经网络只用卷积层，那么无论有多少层，输出都是输入的线性组合，网络的表达能力有限，无法学习到非线性函数。因此 CNN 引入激励函数，激活函数是个非线性函数，常作用于卷积层和全连接层输出的每个神经元（分量/元素），给神经元引入了非线性因素，使网络的表达能力更强，几乎可逼近任意函数，这样神经网络就可应用到众多的非线性模型中。</p>
</section>
<section id="pooling-layer">
<h3 id="pooling-layer">Pooling Layer, 池化层<a class="headerlink" href="#pooling-layer" title="Link to this heading">¶</a></h3>
<p>a <span class="defi">down-sampling</span> strategy
1. Construct better translationally invariant features. 局部平移不变性，当输入有一定的平移时，经池化后输出不会发生改变。使得其特征提取不会因为目标位置的变化而受到较大的影响
2. Learn more compact features. 将某个元素邻域的**总体统计**特征作为网络在该位置的输出 we are taking <strong>a summarized value</strong> over all the values present !!! controls overfitting
3. 缩减模型的大小，简化卷积层的输出
4. 提高计算速度以及提高模型的鲁棒性等。
5. <strong>没有需要学习的参数，只需要定义过滤器的大小以及步长即可</strong></p>
<dl class="simple">
<dt>!!! p “The Dimension After Pooling”</dt><dd><p>Given a $Mtimes Ntimes D$ tensor, if we apply the pooling operator with size $Ktimes K$ and Stride $p$ , what are the dimensions of the output?
- depth has no change
- 在width和height那里就像卷积一样 $text{without padding}=(frac{N-F}{s}+1)times(frac{N-F}{s}+1)$
- $implies (cfrac{M-K}{p}+1)times (cfrac{N-K}{p}+1)times D$</p>
</dd>
</dl>
<p><a href="#id25"><span class="problematic" id="id26">|Pooling stategies||</span></a>
<a href="#id27"><span class="problematic" id="id28">|--|</span></a>–|
<a href="#id11"><span class="problematic" id="id12">|</span></a><a href="#id13"><span class="problematic" id="id14">**</span></a>Max Pooling**|（较常用）is robust to small perturbations.直观理解是能够提取出输入图片中比较显著的特征
<a href="#id15"><span class="problematic" id="id16">**</span></a>Average Pooling**|idk</p>
<aside class="system-message" id="id11">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 267); <em><a href="#id12">backlink</a></em></p>
<p>Inline substitution_reference start-string without end-string.</p>
</aside>
<aside class="system-message" id="id13">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 267); <em><a href="#id14">backlink</a></em></p>
<p>Inline strong start-string without end-string.</p>
</aside>
<aside class="system-message" id="id15">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 267); <em><a href="#id16">backlink</a></em></p>
<p>Inline strong start-string without end-string.</p>
</aside>
<p>&lt;figure markdown=”span”&gt;![](./pics/CNN_17.png){width=60%}&lt;p&gt;yellow&lt;/p&gt;&lt;/figure&gt;</p>
</section>
<section id="flatten-layer-tensor-reshape">
<h3 id="flatten-layer-tensor-reshape">Flatten Layer — Tensor Reshape<a class="headerlink" href="#flatten-layer-tensor-reshape" title="Link to this heading">¶</a></h3>
<p>&lt;div class=”grid” markdown&gt;
&lt;figure markdown=”span”&gt;![](./pics/CNN_18.png){width=60%}&lt;/figure&gt;
&lt;p&gt;the output feature map(matrix) will be converted into vector&lt;br&gt; 将前面卷积层或池化层输出的所有二维特征图一起映射成1个一维的特征向量&lt;/p&gt;
&lt;/div&gt;</p>
</section>
<section id="fully-connected-layer-fc">
<h3 id="fully-connected-layer-fc">Fully- Connected Layer, FC<a class="headerlink" href="#fully-connected-layer-fc" title="Link to this heading">¶</a></h3>
<p>光卷积是不能完成分类任务的，所以就是要后面连 FC层，起到“分类器”的作用
<strong>中间可能有多个FC层，**最后模型输出一个**维度等于类别数（输出的神经元个数）**的**向量</strong></p>
<p>&lt;div class=”grid” markdown&gt;
&lt;figure markdown=”span”&gt;![](./pics/CNN_19.png){width=60%}&lt;/figure&gt;
&lt;figure markdown=”span”&gt;![](./pics/CNN_20.png){width=60%}&lt;/figure&gt;
&lt;/div&gt;</p>
</section>
<section id="softmax">
<h3 id="softmax">softmax<a class="headerlink" href="#softmax" title="Link to this heading">¶</a></h3>
<p>softmax归一化，表示每一类的概率，然后**将得分最高的类别判为输入的类别**
The softmax function is used to map the non-normalized output of a network to a probability distribution.
软最大函数用于将网络的非规范化输出映射到概率分布。</p>
</section>
</section>
<section id="famous-cnn-architectures">
<h2 id="famous-cnn-architectures">Famous CNN Architectures<a class="headerlink" href="#famous-cnn-architectures" title="Link to this heading">¶</a></h2>
<section id="deeper-or-wider">
<h3 id="deeper-or-wider">Deeper or Wider?<a class="headerlink" href="#deeper-or-wider" title="Link to this heading">¶</a></h3>
<p><strong>Deep CNN</strong>：Deeply stacked  Convolution Neural Network</p>
<div class="line-block">
<div class="line-block">
<div class="line">| LeNet-5 | AlexNet | VGG Net | ResNet <a href="#id17"><span class="problematic" id="id18">|</span></a>GoogLeNet</div>
</div>
<div class="line">— | — | — | — | — | — |</div>
<div class="line">Key | 特征稀疏链接 | Relu activation  | smaller filters | ^ |</div>
<div class="line">Activation | Sigmoid | ReLU |  ^|^  |</div>
<div class="line">Advantages | basic architecture</div>
</div>
<aside class="system-message" id="id17">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 308); <em><a href="#id18">backlink</a></em></p>
<p>Inline substitution_reference start-string without end-string.</p>
</aside>
<aside class="system-message">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 309)</p>
<p>Line block ends without a blank line.</p>
</aside>
<p>奠定基础 | GPU | ^ <a href="#id19"><span class="problematic" id="id20">|</span></a>^  |
| Drawbacks | 算力不够 <a href="#id21"><span class="problematic" id="id22">|</span></a>^  |  |  |
| 设计用途 | 手写数字识别 | ImageNet classification with deep convolutional neural networks – NIPS 2012 | Very Deep Convolutional Networks for Large-Scale Image Recognition – ICLR 2015 |  Deep Residual Learning for Image Recognition – CVPR 2016|Going deeper with convolutions – CVPR 2015
| deep CNN |  |  ☑️|☑️  <a href="#id23"><span class="problematic" id="id24">|</span></a>☑️  |</p>
<aside class="system-message" id="id19">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 313); <em><a href="#id20">backlink</a></em></p>
<p>Inline substitution_reference start-string without end-string.</p>
</aside>
<aside class="system-message" id="id21">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 313); <em><a href="#id22">backlink</a></em></p>
<p>Inline substitution_reference start-string without end-string.</p>
</aside>
<aside class="system-message" id="id23">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">C:\Users\zxouyang\CodeProjects\PRIVATE_P\io\docs\source\AI/DL/cnn.rst</span>, line 313); <em><a href="#id24">backlink</a></em></p>
<p>Inline substitution_reference start-string without end-string.</p>
</aside>
<p>!!! p “The Skip-connection was first proposed in ResNet”</p>
</section>
<section id="lenet-5">
<h3 id="lenet-5"><strong>LeNet-5</strong><a class="headerlink" href="#lenet-5" title="Link to this heading">¶</a></h3>
<p><strong>7 Layers</strong> (input layer not counted)</p>
<p><strong>3 Convolution Layers</strong> (C1; C3; C5)</p>
<p><strong>2 Pooling Layers</strong> (S2; S4) — Mean</p>
<p><strong>2 Fully Connected Layers</strong> (F6; Output)</p>
<p><strong>Sigmoid Activation!</strong></p>
<p>Details：</p>
<ol class="arabic simple">
<li><p>subsampling 中会在结果上多加一个偏置项</p></li>
<li><p>S2-C3 sparse connected 生成的16@feature map分别按相邻3个，相邻4个，非相邻4个和全部6个特征图进行feature mapping【因为算力不足，限制了连接数，减少计算开销；这样不同特征图的组合可以使新生成的feature map 学到不同的特征模式 】</p></li>
<li><p>MLP作为分类器</p></li>
<li><p>这里的 faltten 是用CNN</p></li>
</ol>
</section>
<section id="alexnet">
<h3 id="alexnet">AlexNet<a class="headerlink" href="#alexnet" title="Link to this heading">¶</a></h3>
<p>ReLU, max pooling, stride
Data augmentation
Optimizer parameters</p>
</section>
<section id="vgg-net">
<h3 id="vgg-net">VGG Net<a class="headerlink" href="#vgg-net" title="Link to this heading">¶</a></h3>
<p><strong>152 layers for ImageNet.</strong></p>
<p>💡 <strong>Key Idea of VGG</strong>: Replace the large convolution filter by stacking some <strong>smaller convolution filters.</strong></p>
<ol class="arabic simple">
<li><p><strong>More concise and generalizable.</strong></p></li>
<li><p><strong>Smaller filters can achieve better performance than larger filters. smaller filters 堆积可以比 larger更高</strong></p></li>
<li><p><strong>Demonstrate that increase depth can boost performance. 深度可提高表现</strong></p></li>
</ol>
<p>5x5 conv = two 3x3 conv
7x7 conv = three 3x3 conv</p>
</section>
<section id="residual-net-resnet">
<h3 id="residual-net-resnet">Residual Net, <strong>ResNet</strong><a class="headerlink" href="#residual-net-resnet" title="Link to this heading">¶</a></h3>
<p>keep origin information</p>
<p>Skip-connection
Batch-normalization
Bottleneck block</p>
</section>
<section id="dense-net">
<h3 id="dense-net"><strong>Dense Net</strong><a class="headerlink" href="#dense-net" title="Link to this heading">¶</a></h3>
</section>
<section id="googlenet">
<h3 id="googlenet"><strong>GoogleNet</strong><a class="headerlink" href="#googlenet" title="Link to this heading">¶</a></h3>
<p>There are some parallel polar level.
Okay? Blocks in in a certain layer that means You will send. You will
send I input. Okay, into different convolutions. Okay. And let’s go
through different architectures. And then we merged guys okay, into a
final okay output. Okay, So this is a key idea. Okay, significant
difference. Okay, of Google, net with different, other, different neural
networks. Okay. But yeah you can try this. Okay. But we will not Talk
about the details of this neural networks, Okay</p>
</section>
<section id="light-weight-networks">
<h3 id="light-weight-networks">Light-weight networks<a class="headerlink" href="#light-weight-networks" title="Link to this heading">¶</a></h3>
<p>!!! p “Performance on computation limits”</p>
<p>![](./pics/CNN_23.png){width=60%}
![](./pics/CNN_24.png){width=60%}</p>
<dl class="simple">
<dt>!!! danger “a depthwise convolution involves applying a separate 3x3 filter to each input channel.”</dt><dd><p>&gt; &gt; For a depthwise 3x3 convolution, the number of  input channels and output channels are both 32, how many parameters does this convolution layer have ？
&gt;
&gt; $3*3*32$</p>
</dd>
</dl>
<p><strong>Group convolution:</strong></p>
</section>
</section>
<section id="practical-exercise">
<h2 id="practical-exercise">Practical Exercise<a class="headerlink" href="#practical-exercise" title="Link to this heading">¶</a></h2>
</section>
<section id="parameters-initialization">
<h2 id="parameters-initialization">Parameters Initialization<a class="headerlink" href="#parameters-initialization" title="Link to this heading">¶</a></h2>
<p>快速 shrikage to point</p>
</section>
<section id="bach-normalization">
<h2 id="bach-normalization">Bach Normalization<a class="headerlink" href="#bach-normalization" title="Link to this heading">¶</a></h2>
</section>
<section id="application">
<h2 id="application">Application<a class="headerlink" href="#application" title="Link to this heading">¶</a></h2>
</section>
<section id="edge-detection">
<h2 id="edge-detection">Edge Detection<a class="headerlink" href="#edge-detection" title="Link to this heading">¶</a></h2>
<p>如上图所示：输入是一个6*6的矩阵，输入是一个左白右灰的图片（白色部分对应的矩阵值大于0，灰色部分的值为0），中间有一道竖线分割；中间的垂直过滤器是一个3*3的矩阵，由白灰黑三个部分组成，矩阵三列的值分别大于0，等于0和小于0；输出的结果矩阵中，中间的两列大于0，即输出的图片中间部分为白色，也就是说经过卷积之后，成功的检测出了原始图片中间存在的垂直竖线。</p>
</section>
<section id="exercise">
<h2 id="exercise">Exercise<a class="headerlink" href="#exercise" title="Link to this heading">¶</a></h2>
<p>&gt; &gt;(in L5 in AMA564), input $inR^{5times5}$,kernel $inR^{3times3}$,bias=-500, activation function is ReLU</p>
</section>
<section id="code">
<h2 id="code">code<a class="headerlink" href="#code" title="Link to this heading">¶</a></h2>
<p>[卷积神经网络（浅显易懂）-吴恩达课程学习]: <a class="reference external" href="https://zhuanlan.zhihu.com/p/35251749/">https://zhuanlan.zhihu.com/p/35251749/</a></p>
<p>[神经网络及CNN中的通道、共享权重、特征映射等的理解_zhu_Lydia的博客-CSDN博客_cnn的通道]:<a class="reference external" href="https://blog.csdn.net/zhu_Lydia/article/details/88567648">https://blog.csdn.net/zhu_Lydia/article/details/88567648</a></p>
<p>[Convolutional Neural Network Architecture | CNN Architecture]:<a class="reference external" href="https://www.analyticsvidhya.com/blog/2020/10/what-is-the-convolutional-neural-network-architecture/">https://www.analyticsvidhya.com/blog/2020/10/what-is-the-convolutional-neural-network-architecture/</a></p>
<p>[Convolutional Neural Network | Deep Learning | Developers Breach]: <a class="reference external" href="https://developersbreach.com/convolution-neural-network-deep-learning/">https://developersbreach.com/convolution-neural-network-deep-learning/</a></p>
</section>
</section>


          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2024, coconut.
              
          </div>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 7.3.7.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>