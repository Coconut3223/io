<!DOCTYPE html>

<html lang="zh-CN" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../_static/javascripts/modernizr.js"></script>
  
  
  
    <title>OpenNMT &#8212; HomePage</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=83e35b93" />
    <link rel="stylesheet" type="text/css" href="../_static/material.css?v=79c92029" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/css/def.css?v=5a9d86bd" />
    <script src="../_static/documentation_options.js?v=7d86a446"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=6dbb43f8"></script>
    <script src="../_static/translations.js?v=beaddf03"></script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=blue-grey data-md-color-accent=blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#NLP/opennmt" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../index.html" title="HomePage"
           class="md-header-nav__button md-logo">
          
            <i class="md-icon">&#xe869</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">Cocobook</span>
          <span class="md-header-nav__topic"> OpenNMT </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder=""Search""
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
      
  
  <script src="../_static/javascripts/version_dropdown.js"></script>
  <script>
    var json_loc = "../"versions.json"",
        target_loc = "../../",
        text = "Versions";
    $( document ).ready( add_version_dropdown(json_loc, target_loc, text));
  </script>
  

    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
          <li class="md-tabs__item"><a href="../index.html" class="md-tabs__link">HomePage</a></li>
            
            <li class="md-tabs__item"><a href="../AI/index.html" class="md-tabs__link">AI</a></li>
            
            <li class="md-tabs__item"><a href="../python/index.html" class="md-tabs__link">Python</a></li>
            
            <li class="md-tabs__item"><a href="index.html" class="md-tabs__link">NLP</a></li>
            
            <li class="md-tabs__item"><a href="../SQL/main.html" class="md-tabs__link">SQL</a></li>
            
            <li class="md-tabs__item"><a href="../utils/index.html" class="md-tabs__link">Utils</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../index.html" title="HomePage" class="md-nav__button md-logo">
      
        <i class="md-icon">&#xe869</i>
      
    </a>
    <a href="../index.html"
       title="HomePage">Cocobook</a>
  </label>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">"Contents"</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#nlp-opennmt--page-root" class="md-nav__link">OpenNMT</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#data-gathering-and-processing" class="md-nav__link">Data Gathering and Processing</a>
        </li>
        <li class="md-nav__item"><a href="#tokenization-sub-wording" class="md-nav__link">Tokenization / Sub-wording</a>
        </li>
        <li class="md-nav__item"><a href="#data-splitting" class="md-nav__link">Data Splitting</a>
        </li>
        <li class="md-nav__item"><a href="#create-the-training-configuration-file" class="md-nav__link">Create the Training Configuration File</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#example" class="md-nav__link">Example</a>
        </li>
        <li class="md-nav__item"><a href="#content" class="md-nav__link">Content</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#build-vocabulary" class="md-nav__link">Build Vocabulary</a>
        </li>
        <li class="md-nav__item"><a href="#check-gpu" class="md-nav__link">Check GPU</a>
        </li>
        <li class="md-nav__item"><a href="#traning" class="md-nav__link">Traning</a>
        </li>
        <li class="md-nav__item"><a href="#applying" class="md-nav__link">Applying</a>
        </li>
        <li class="md-nav__item"><a href="#evaluation" class="md-nav__link">Evaluation</a>
        </li>
        <li class="md-nav__item"><a href="#model" class="md-nav__link">model</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#ensemble-decoding" class="md-nav__link">Ensemble Decoding</a>
        </li>
        <li class="md-nav__item"><a href="#release-model" class="md-nav__link">Release Model</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#using-pre-trained-nmt-models" class="md-nav__link">Using pre-trained NMT models</a>
        </li>
        <li class="md-nav__item"><a href="#multilingual-neural-machine-translation-mnmt" class="md-nav__link">Multilingual Neural Machine Translation，MNMT</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#tensorboard" class="md-nav__link">tensorboard</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#ref" class="md-nav__link">Ref</a>
        </li>
        <li class="md-nav__item"><a href="#temp" class="md-nav__link">Temp</a>
        </li></ul>
            </nav>
        </li>
  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <section id="opennmt">
<h1 id="nlp-opennmt--page-root">OpenNMT<a class="headerlink" href="#nlp-opennmt--page-root" title="Link to this heading">¶</a></h1>
<p><span class="defi">Open-Source Toolkit for Neural Machine Translation</span> 。
<span class="defi">Neural Machine Translation NMT 神经机器翻译</span></p>
<div class="line-block">
<div class="line">The system is successor to <strong>seq2seq-attn</strong> developed at Harvard, and has been completely rewritten for ease of efficiency, readability, and generalizability.</div>
<div class="line">It includes vanilla NMT models along with support for <strong>attention, gating, stacking, input feeding, regularization, beam search and all other options</strong> necessary for state-of-the-art performance.</div>
<div class="line">The project is fully self-contained depending on minimal number of external Lua libraries and including also a simple language independent reversible tokenization and detokenization tools. 完全独立，只有少部分依赖 标记 &amp; 去标记 的东西。</div>
</div>
<div class="admonition-paper-abstract admonition note">
<p class="admonition-title">官方 paper 【Abstract】</p>
<div class="line-block">
<div class="line">We describe an open-source toolkit for neural machine translation (NMT). The toolkit <strong>prioritizes efficiency, modularity, and extensibility with the goal of supporting NMT research into model architectures, feature representations, and source modalities</strong>, while maintaining competitive performance and reasonable training requirements. The toolkit consists of modeling and translation support, as well as detailed pedagogical documentation about the underlying techniques.</div>
<div class="line">[Open-Source Toolkit for Neural Machine Translation]</div>
</div>
</div>
<section id="data-gathering-and-processing">
<h2 id="data-gathering-and-processing">Data Gathering and Processing<a class="headerlink" href="#data-gathering-and-processing" title="Link to this heading">¶</a></h2>
<ul>
<li><dl>
<dt>包括：至少4个</dt><dd><div class="line-block">
<div class="line">两种语言分为 ① 源 &lt;kbd&gt;src.txt&lt;/kbd&gt; ② 目标 &lt;kbd&gt;tgt.txt&lt;/kbd&gt;；从数据集上：分为训练集和验证集。</div>
<div class="line">每行一个sample，&lt;kbd&gt;src.txt&lt;/kbd&gt; 和 &lt;kbd&gt;tgt.txt&lt;/kbd&gt; 相互对应。Each file has a sentence/segment per line, and it is matching translation in the same line in the other file. This is what the “Moses” file format means.</div>
</div>
<div class="admonition- admonition note">
<p class="admonition-title">多源怎么办？有偏重怎么办？</p>
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption"><span class="caption-text">config.yml</span><a class="headerlink" href="#id1" title="Link to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">data</span><span class="p">:</span>
<span class="w">    </span><span class="nt">corpus_1</span><span class="p">:</span>
<span class="w">        </span><span class="nt">path_src</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">src1_train.txt</span>
<span class="w">        </span><span class="nt">path_tgt</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tgt1_train.txt</span>
<span class="w">        </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">corpus_2</span><span class="p">:</span>
<span class="w">        </span><span class="nt">path_src</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">src2_train.txt</span>
<span class="w">        </span><span class="nt">path_tgt</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tgt2_train.txt</span>
<span class="w">        </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="w">    </span><span class="nt">valid</span><span class="p">:</span>
<span class="w">        </span><span class="nt">path_src</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">src2_valid.txt</span>
<span class="w">        </span><span class="nt">path_tgt</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tgt2_valid.txt</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">...</span>
</pre></div>
</div>
</div>
</div>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>内容【see ## Tokenization / Sub-wording】</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>token 形式，以&lt;u&gt;空格&lt;/u&gt;分词</dt><dd><ul>
<li><p>本身一个就是最小token形式存在： 英、法：不需要处理</p></li>
<li><p>不以特殊标记分割词的：中：&lt;u&gt;需要分词&lt;/u&gt;</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<div class="admonition-tokenizer admonition note">
<p class="admonition-title">如果不先分词传进去，也可以指定分词  <code class="docutils literal notranslate"><span class="pre">[tokenizer]</span></code></p>
<p>而一般用 &lt;u&gt;Sentence Piece&lt;/u&gt; 基于语料训练一个 tokenizer，类似于 jieba，&lt;U&gt;会形成固定大小的词表&lt;/U&gt;。这会影响后来的 &lt;u&gt; <code class="docutils literal notranslate"><span class="pre">vocab_size</span></code> &lt;/u&gt;</p>
<blockquote>
<div><div class="literal-block-wrapper docutils container" id="id2">
<div class="code-block-caption"><span class="caption-text">config.yml</span><a class="headerlink" href="#id2" title="Link to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">data</span><span class="p">:</span>
<span class="w">    </span><span class="nt">corpus_1</span><span class="p">:</span>
<span class="w">        </span><span class="nt">path_src</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">src1_train.txt</span>
<span class="w">        </span><span class="nt">path_tgt</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tgt1_train.txt</span>
<span class="w">        </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">        </span><span class="nt">transforms</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">tokenizer</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
</div>
</div></blockquote>
</div>
</li>
</ul>
</section>
<section id="tokenization-sub-wording">
<h2 id="tokenization-sub-wording">Tokenization / Sub-wording<a class="headerlink" href="#tokenization-sub-wording" title="Link to this heading">¶</a></h2>
<p>However, an MT model can only learn a specific number of vocabulary tokens due to limited hardware resources. &lt;u&gt;To solve this issue, sub-words are used instead of whole words.&lt;/u&gt; At translation time, when the model sees a new word/token that looks like a word/token it has in the vocabulary, it still can try to continue the translation instead of marking this word as “unknown” or “unk”.</p>
<p>因为硬件资源有限，MT model 只能学一定量的词汇。为了让它在碰见新的词汇能继续翻译而不是标记成&lt;kbd&gt;unknown&lt;/kbd&gt; or &lt;kbd&gt;UNK&lt;/kbd&gt;.</p>
<div class="admonition-the-small-units admonition note">
<p class="admonition-title">最小单元 the small units是什么？</p>
<div class="admonition-u-english-u admonition hint">
<p class="admonition-title">&lt;u&gt;English&lt;/u&gt;</p>
<p>▁Hav ing ▁considered ▁the ▁report ▁of ▁the ▁Committee ▁on ▁Conferences ▁for ▁ 2 0 0 6 Official ▁Record s ▁of ▁the ▁General ▁Assembly , ▁S ixty - first ▁Session , ▁Supplement ▁No . ▁ 3 2 ▁( A / 6 1 / 3 2 ). ▁and ▁the ▁relevant ▁reports ▁of ▁the ▁Secretary - General , A / 6 1 / 1 2 9 ▁and ▁Add . 1 ▁and ▁A / 6 1 / 3 0 0 .&lt;/kbd&gt;</p>
</div>
</div>
</section>
<section id="data-splitting">
<h2 id="data-splitting">Data Splitting<a class="headerlink" href="#data-splitting" title="Link to this heading">¶</a></h2>
<p>tra, test, valid</p>
</section>
<section id="create-the-training-configuration-file">
<h2 id="create-the-training-configuration-file">Create the Training Configuration File<a class="headerlink" href="#create-the-training-configuration-file" title="Link to this heading">¶</a></h2>
<p>Create the &lt;u&gt;YAML configuration file&lt;/u&gt;. On a regular machine, you can create it manually or with &lt;u&gt;nano&lt;/u&gt;.</p>
<section id="example">
<h3 id="example">Example<a class="headerlink" href="#example" title="Link to this heading">¶</a></h3>
<div class="literal-block-wrapper docutils container" id="id3">
<div class="code-block-caption"><span class="caption-text">config.yml</span><a class="headerlink" href="#id3" title="Link to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">save_data</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">run</span><span class="w">  </span><span class="c1"># Where the samples will be written</span>

<span class="c1"># Training files</span>
<span class="nt">data</span><span class="p">:</span>
<span class="w">    </span><span class="nt">corpus_1</span><span class="p">:</span>
<span class="w">        </span><span class="nt">path_src</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">UN.en-fr.fr-filtered.fr.subword.train</span>
<span class="w">        </span><span class="nt">path_tgt</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">UN.en-fr.en-filtered.en.subword.train</span>
<span class="w">        </span><span class="nt">transforms</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">filtertoolong</span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="nt">valid</span><span class="p">:</span>
<span class="w">        </span><span class="nt">path_src</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">UN.en-fr.fr-filtered.fr.subword.dev</span>
<span class="w">        </span><span class="nt">path_tgt</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">UN.en-fr.en-filtered.en.subword.dev</span>
<span class="w">        </span><span class="nt">transforms</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">filtertoolong</span><span class="p p-Indicator">]</span>

<span class="nt">src_vocab</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">run/source.vocab</span><span class="w">  </span><span class="c1"># Vocabulary files, generated by onmt_build_vocab</span>
<span class="nt">tgt_vocab</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">run/target.vocab</span>

<span class="nt">src_vocab_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">50000</span><span class="w">  </span><span class="c1"># Max Vocabulary size</span>
<span class="nt">tgt_vocab_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">50000</span><span class="w">  </span><span class="c1"># Max Vocabulary size</span>

<span class="c1"># Filter out source/target longer than n if [filtertoolong] enabled</span>
<span class="nt">src_seq_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">150</span>
<span class="nt">src_seq_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">150</span>

<span class="c1"># Tokenization options</span>
<span class="nt">src_subword_model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">source.model</span>
<span class="nt">tgt_subword_model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">target.model</span>

<span class="c1"># Where to save the log file and the output models/checkpoints</span>
<span class="nt">log_file</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">train.log</span>
<span class="nt">save_model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">models/model.fren</span>

<span class="c1"># Checkpoint</span>
<span class="nt">save_checkpoint_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1000</span><span class="w">  </span><span class="c1"># Default: 5000 - Save a model checkpoint for each n</span>
<span class="nt">keep_checkpoint</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span><span class="w">  </span><span class="c1"># To save space, limit checkpoints to last n</span>

<span class="nt">seed</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3435</span>

<span class="c1"># Default: 100000 - Train the model to max n steps</span>
<span class="c1"># Increase to 200000 or more for large datasets</span>
<span class="c1"># For fine-tuning, add up the required steps to the original steps</span>
<span class="nt">train_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3000</span>

<span class="nt">valid_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1000</span><span class="w"> </span><span class="c1"># Default: 10000 - Run validation after n steps</span>

<span class="nt">early_stopping</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span><span class="w">  </span><span class="c1"># Stop training if it does not imporve after n validations</span>
<span class="nt">report_every</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100</span>

<span class="c1"># GPU</span>
<span class="nt">world_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span><span class="w">  </span><span class="c1"># Number of GPUs, and</span>
<span class="nt">gpu_ranks</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0</span><span class="p p-Indicator">]</span><span class="w">  </span><span class="c1"># IDs of GPUs</span>

<span class="c1"># Batching</span>
<span class="nt">bucket_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">262144</span>
<span class="nt">num_workers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w">  </span><span class="c1"># Default: 2, set to 0 when RAM out of memory</span>
<span class="nt">batch_type</span><span class="p">:</span><span class="w"> </span><span class="s">"tokens"</span>
<span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4096</span><span class="w">   </span><span class="c1"># Tokens per batch, change when CUDA out of memory</span>
<span class="nt">valid_batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2048</span>
<span class="nt">max_generator_batches</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="nt">accum_count</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">4</span><span class="p p-Indicator">]</span>
<span class="nt">accum_steps</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0</span><span class="p p-Indicator">]</span>

<span class="c1"># Optimization</span>
<span class="nt">model_dtype</span><span class="p">:</span><span class="w"> </span><span class="s">"fp16"</span>
<span class="nt">optim</span><span class="p">:</span><span class="w"> </span><span class="s">"adam"</span>
<span class="nt">learning_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="nt">warmup_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1000</span><span class="w">  </span><span class="c1"># Default: 4000 - for large datasets, try up to 8000</span>
<span class="nt">decay_method</span><span class="p">:</span><span class="w"> </span><span class="s">"noam"</span>
<span class="nt">adam_beta2</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.998</span>
<span class="nt">max_grad_norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">label_smoothing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="nt">param_init</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">param_init_glorot</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">normalization</span><span class="p">:</span><span class="w"> </span><span class="s">"tokens"</span>

<span class="c1"># Model</span>
<span class="nt">encoder_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">transformer</span>
<span class="nt">decoder_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">transformer</span>
<span class="nt">position_encoding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">enc_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="nt">dec_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="nt">heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="nt">hidden_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="nt">word_vec_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="nt">transformer_ff</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2048</span>
<span class="nt">dropout_steps</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0</span><span class="p p-Indicator">]</span>
<span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.1</span><span class="p p-Indicator">]</span>
<span class="nt">attention_dropout</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.1</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
</div>
</section>
<section id="content">
<h3 id="content">Content<a class="headerlink" href="#content" title="Link to this heading">¶</a></h3>
<ul>
<li><dl>
<dt><code class="docutils literal notranslate"><span class="pre">src_vocab_size=50k</span></code>  &amp;  <code class="docutils literal notranslate"><span class="pre">tgt_vocab_size=50k</span></code>  Vocabulary size</dt><dd><ul class="simple">
<li><p>default 50k</p></li>
<li><p>如果使用 &lt;u&gt;Sentence Piece&lt;/u&gt; 得到的tokenizer来分词，这两个 params = size_of_SentencePiece</p></li>
<li><p>但事先分好词进去，就会直接  <code class="docutils literal notranslate"><span class="pre">counters</span></code>  统计。统计的大小看语料的丰富的程度。</p></li>
</ul>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="o">[</span><span class="m">2023</span>-12-07<span class="w"> </span><span class="m">14</span>:23:22,059<span class="w"> </span>INFO<span class="o">]</span><span class="w"> </span>Counters<span class="w"> </span>src:<span class="w"> </span><span class="m">17008</span>
<span class="o">[</span><span class="m">2023</span>-12-07<span class="w"> </span><span class="m">14</span>:23:22,060<span class="w"> </span>INFO<span class="o">]</span><span class="w"> </span>Counters<span class="w"> </span>tgt:<span class="w"> </span><span class="m">16939</span>
</pre></div>
</div>
</dd>
</dl>
</li>
</ul>
<p>For larger datasets, consider increasing: train_steps, valid_steps, warmup_steps, save_checkpoint_steps, keep_checkpoint</p>
<ul class="simple">
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">train_steps</span></code></dt><dd><p>for datasets with a few millions of sentences, consider using a value between 100000 and 200000, or more!
- &lt;u&gt; <code class="docutils literal notranslate"><span class="pre">early_stopping:</span> <span class="pre">int</span></code> &lt;/u&gt; can help stop the training when there is no considerable improvement.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">valid_steps</span></code></dt><dd><p>10000 can be good if the value train_steps is big enough.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">warmup_steps</span></code></dt><dd><p>obviously, its value must be less than train_steps. Try 4000 and 8000 values.</p>
</dd>
</dl>
</li>
</ul>
</section>
</section>
<section id="build-vocabulary">
<h2 id="build-vocabulary">Build Vocabulary<a class="headerlink" href="#build-vocabulary" title="Link to this heading">¶</a></h2>
<p>对于大的数据集来说，用所有的词进行训练是 not feasible. 所以需要构建小的词库。</p>
<p>Main purpose: To extract a specific set of vocabulary(usually &lt;u&gt;betweeen 32k and 100k &lt;/u&gt;words) from the traning set.</p>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">config.yml</span><a class="headerlink" href="#id4" title="Link to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">...</span>
<span class="nt">src_vocab</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">run/src.vocab</span><span class="w">  </span><span class="c1"># Vocabulary files, generated by onmt_build_vocab</span>
<span class="nt">tgt_vocab</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">run/tgt.vocab</span>

<span class="nt">src_vocab_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">50000</span><span class="w">  </span><span class="c1"># MAX Vocabulary size</span>
<span class="nt">tgt_vocab_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">50000</span><span class="w">  </span><span class="c1"># MAX Vocabulary size</span>

<span class="nt">src_words_min_frequency</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span><span class="w"> </span><span class="c1"># 單獨運行無意義的感覺</span>
<span class="nt">tgt_words_min_frequency</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2 `</span>
</pre></div>
</div>
</div>
<p>&lt;kbd&gt;onmt_build_vocab -config config.yaml -n_sample -1 -num_threads 2&lt;/kbd&gt;</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-config</span></code>  data…&amp;词典大小和保存位置</p></li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">-n_sample</span></code></dt><dd><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">=-1</span></code>  on <strong>all</strong> the segment in the training dataset</p></li>
</ul>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">-num_threads</span></code> : change it to match the number of CPUs to run it faster</p></li>
</ul>
<div class="admonition-example admonition hint">
<p class="admonition-title">example</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>INFO<span class="o">]</span><span class="w"> </span>Counter<span class="w"> </span>vocab<span class="w"> </span>from<span class="w"> </span>-1<span class="w"> </span>samples.
<span class="o">[</span>INFO<span class="o">]</span><span class="w"> </span><span class="nv">n_sample</span><span class="o">=</span>-1:<span class="w"> </span>Build<span class="w"> </span>vocab<span class="w"> </span>on<span class="w"> </span>**full**<span class="w"> </span>datasets.
<span class="o">[</span>INFO<span class="o">]</span><span class="w"> </span>*<span class="w"> </span>Transform<span class="w"> </span>statistics<span class="w"> </span><span class="k">for</span><span class="w"> </span>corpus_1<span class="o">(</span><span class="m">50</span>.00%<span class="o">)</span>:
*<span class="w"> </span>FilterTooLongStats<span class="o">(</span><span class="nv">filtered</span><span class="o">=</span><span class="m">2138</span><span class="o">)</span>
<span class="o">[</span>INFO<span class="o">]</span><span class="w"> </span>*<span class="w"> </span>Transform<span class="w"> </span>statistics<span class="w"> </span><span class="k">for</span><span class="w"> </span>corpus_1<span class="o">(</span><span class="m">50</span>.00%<span class="o">)</span>:
*<span class="w"> </span>FilterTooLongStats<span class="o">(</span><span class="nv">filtered</span><span class="o">=</span><span class="m">2032</span><span class="o">)</span>
<span class="o">[</span>INFO<span class="o">]</span><span class="w"> </span>Counters<span class="w"> </span>src:14705
<span class="o">[</span>INFO<span class="o">]</span><span class="w"> </span>Counters<span class="w"> </span>tgt:11884
</pre></div>
</div>
</div>
</section>
<section id="check-gpu">
<h2 id="check-gpu">Check GPU<a class="headerlink" href="#check-gpu" title="Link to this heading">¶</a></h2>
<p>&lt;kbd&gt;nvidia-smi -L&lt;/kbd&gt; Check if the GPU is active</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">gpu_memory</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">mem_get_info</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">"Free GPU memory:"</span><span class="p">,</span> <span class="n">gpu_memory</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="s2">"out of:"</span><span class="p">,</span> <span class="n">gpu_memory</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="go">True</span>
<span class="go">Tesla T4</span>
<span class="go">Free GPU memory: 15007.75 out of: 15109.75</span>
</pre></div>
</div>
</section>
<section id="traning">
<h2 id="traning">Traning<a class="headerlink" href="#traning" title="Link to this heading">¶</a></h2>
<ol class="arabic">
<li><p>remove existed model: &lt;kbd&gt;rm -rf drive/MyDrive/nmt/models/&lt;/kbd&gt;</p></li>
<li><dl>
<dt>Train the NMT model: &lt;kbd&gt;onmt_train -config config.yaml&lt;/kbd&gt;</dt><dd><ul>
<li><p>If the traning stopped, and we want to continue it from a specific checkpoint: &lt;kbd&gt;onmt_train -config config.yaml -train_from models/model.fren_step_3000.pt&lt;/kbd&gt;</p>
<blockquote>
<div><div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">config.yml</span><a class="headerlink" href="#id5" title="Link to this code">¶</a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">train_steps</span><span class="w"> </span><span class="c1"># &gt; train_from 的数字</span>
</pre></div>
</div>
</div>
</div></blockquote>
</li>
</ul>
</dd>
</dl>
</li>
</ol>
<ul class="simple">
<li><p>debug mode: &lt;kbd&gt;dmesg -T&lt;/kbd&gt;</p></li>
</ul>
</section>
<section id="applying">
<h2 id="applying">Applying<a class="headerlink" href="#applying" title="Link to this heading">¶</a></h2>
<p>Translation Options:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-model</span></code> : model(s) used</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-src</span></code> : source file</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-output</span></code> : filename to write result</p></li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">-gpu</span></code><span class="classifier">GPU ID</span></dt><dd><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">=0</span></code> : 1 GPU</p></li>
<li><p>: CPU</p></li>
</ul>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">-min_length[optional]</span></code> :  to avoid empty translations</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-verbose[optional]</span></code> : if you want to print translations</p></li>
</ul>
<div class="admonition-example admonition hint">
<p class="admonition-title">example</p>
<ol class="arabic simple">
<li><p>&lt;kbd&gt;onmt_translate -model models/model.fren_step_3000.pt -src UN.en-fr.fr-filtered.fr.subword.test -output UN.en.translated -gpu 0 -min_length 1&lt;/kbd&gt;</p></li>
<li><p>Check the first line of result &lt;kbd&gt;head -n 1 UN.en.translated&lt;/kbd&gt;</p></li>
</ol>
<div class="line-block">
<div class="line">&lt;u&gt; Using sub-word&lt;/u&gt;</div>
<div class="line">▁Recalling ▁its ▁relevant ▁resolutions , ▁including ▁resolution ▁ 5 8 / 2 9 2 ▁of ▁ 6 ▁May ▁ 2 0 0 4 , ▁as ▁well ▁as ▁th ose ▁adopted ▁at ▁its ▁tenth ▁emergency ▁special ▁session ,</div>
<div class="line">&lt;u&gt;Using word&lt;/u&gt;</div>
<div class="line">Recalling its relevant resolutions, including resolution 58/292 of 6 May 2004, as well as those adopted at its tenth emergency special session,</div>
</div>
</div>
</section>
<section id="evaluation">
<h2 id="evaluation">Evaluation<a class="headerlink" href="#evaluation" title="Link to this heading">¶</a></h2>
</section>
<section id="model">
<h2 id="model">model<a class="headerlink" href="#model" title="Link to this heading">¶</a></h2>
<section id="ensemble-decoding">
<h3 id="ensemble-decoding">Ensemble Decoding<a class="headerlink" href="#ensemble-decoding" title="Link to this heading">¶</a></h3>
<p>During translation, instead of adding one model/checkpoint to the -model argument, add multiple checkpoints. For example, try the two last checkpoints. Does it improve quality of translation? Does it affect translation seepd?</p>
<ul class="simple">
<li><p><strong>Averaging Models</strong></p></li>
</ul>
<div class="line-block">
<div class="line">&lt;kbd&gt;python3 average_models.py -models model_step_xxx.pt model_step_yyy.pt -output model_avg.pt&lt;/kbd&gt;</div>
<div class="line">Average multiple models into one model using the average_models.py script, and see how this affects performance.</div>
</div>
</section>
<section id="release-model">
<h3 id="release-model">Release Model<a class="headerlink" href="#release-model" title="Link to this heading">¶</a></h3>
<p>see how it reduce the model size.</p>
<p>&lt;kbd&gt;onmt_release_model –model model.pt –output model_released.pt&lt;/kbd&gt;</p>
</section>
</section>
<section id="using-pre-trained-nmt-models">
<h2 id="using-pre-trained-nmt-models">Using pre-trained NMT models<a class="headerlink" href="#using-pre-trained-nmt-models" title="Link to this heading">¶</a></h2>
<div class="line-block">
<div class="line">For low-resource languages(up to 15m), using directly or fine-tuning mBART can give better results.</div>
<div class="line">For high-resource languages, training a baseline model from scratch can outperform mBART.</div>
<div class="line">Then, applying mixed fine-tuning (Chu et al., 2017) on this new baseline using in-house data can even achieve better gains in terms of Machine Translation quality. Check this code snippet if you would like to try mBART. You can also convert M2M-100 model to the CTranslate2 format for better efficiency as explained here.</div>
</div>
</section>
<section id="multilingual-neural-machine-translation-mnmt">
<h2 id="multilingual-neural-machine-translation-mnmt">Multilingual Neural Machine Translation，MNMT<a class="headerlink" href="#multilingual-neural-machine-translation-mnmt" title="Link to this heading">¶</a></h2>
<p><strong>Advantages：</strong></p>
<ol class="arabic simple">
<li><p>help a &lt;u&gt;low-resource&lt;/u&gt; language acquire extra knowledge from other languages</p></li>
<li><p>tend to generalize better due to exposure to diverse languages. This particular phenomenon is known as <strong>translation Transfer Learning or Knowledge Transfer</strong> (Dabre et al., 2020).</p></li>
<li><p>Languages that do not share the same alphabet cannot achieve the same linguistic benefits from a multilingual NMT model. Still, researchers investigate approaches like transliteration to increase knowledge transfer between languages that belong to the same language family, but use different alphabets. For example, using this transliteration trick, my Indic-to-English multilingual NMT model can translate from 10 Indic languages to English.</p></li>
</ol>
<p><strong>Notes：</strong></p>
<ol class="arabic">
<li><p>&lt;u&gt;shuffle&lt;/u&gt; dataset</p></li>
<li><dl>
<dt>check banlanced -&gt; &lt;u&gt;over-sampling&lt;/u&gt;</dt><dd><ul>
<li><dl>
<dt>giving <strong>weights</strong> to datasets</dt><dd><div class="admonition-en-10-million-zh-2-million-math-implies-weight-of-en-1-weight-of-zh-5 admonition hint">
<p class="admonition-title">En: 10 million, zh: 2 million  <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>  </mtext><mo>⟹</mo><mtext>  </mtext></mrow><annotation encoding="application/x-tex">\implies</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:0.549em;vertical-align:-0.024em;"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">⟹</span><span class="mspace" style="margin-right:0.2778em;"></span></span></span></span></span>  weight of En = 1, weight of zh = 5</p>
</div>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl>
<dt>&lt;u&gt;[Optional]&lt;/u&gt; add a special token to the start of each sentence. In this case, you will have to add these tokens to your SentencePiece model through the option  <code class="docutils literal notranslate"><span class="pre">--user_defined_symbols</span></code> . However, some researchers believe this step is optional.</dt><dd><div class="admonition-en-en-zh-zh admonition hint">
<p class="admonition-title">En:  <code class="docutils literal notranslate"><span class="pre">&lt;en&gt;</span></code> , zh:  <code class="docutils literal notranslate"><span class="pre">&lt;zh&gt;</span></code></p>
</div>
</dd>
</dl>
</li>
<li><p>Integrating other data augmentation approaches like Back-Translation can still be useful.</p></li>
<li><dl class="simple">
<dt>pre-trained NMT models</dt><dd><p>For low-resource languages(up to 15m), using directly or fine-tuning mBART can give better results.
For high-resource languages, training a baseline model from scratch can outperform mBART.
Then, applying &lt;u&gt;mixed fine-tuning&lt;/u&gt; (Chu et al., 2017) on this new baseline using in-house data can even achieve better gains in terms of Machine Translation quality.</p>
</dd>
</dl>
</li>
</ol>
<p>[Notes on Multilingual Machine Translation]</p>
<p>You can also convert M2M-100 model to the CTranslate2 format for better efficiency as explained here.</p>
<section id="tensorboard">
<h3 id="tensorboard">tensorboard<a class="headerlink" href="#tensorboard" title="Link to this heading">¶</a></h3>
<p>[Running TensorBoard](<a class="reference external" href="https://forum.opennmt.net/t/running-tensorboard/4242">https://forum.opennmt.net/t/running-tensorboard/4242</a>)</p>
</section>
</section>
<section id="ref">
<h2 id="ref">Ref<a class="headerlink" href="#ref" title="Link to this heading">¶</a></h2>
<p>[神经机器翻译（NMT）的一些重要资源分享](<a class="reference external" href="https://zhuanlan.zhihu.com/p/29338282">https://zhuanlan.zhihu.com/p/29338282</a>)
[OpenNMT-py Tutorial](<a class="reference external" href="https://github.com/ymoslem/OpenNMT-Tutorial/tree/main">https://github.com/ymoslem/OpenNMT-Tutorial/tree/main</a>)</p>
<p>[Notes on Multilingual Machine Translation]: <a class="reference external" href="https://blog.machinetranslation.io/multilingual-nmt/">https://blog.machinetranslation.io/multilingual-nmt/</a></p>
<p>[](<a class="reference external" href="https://leonis.cc/sui-sui-nian/2022-12-16-opennmt-tutorial-quickstart.html">https://leonis.cc/sui-sui-nian/2022-12-16-opennmt-tutorial-quickstart.html</a>)</p>
<p>[Open-Source Toolkit for Neural Machine Translation]:<a class="reference external" href="https://aclanthology.org/P17-4012.pdf">https://aclanthology.org/P17-4012.pdf</a></p>
</section>
<section id="temp">
<h2 id="temp">Temp<a class="headerlink" href="#temp" title="Link to this heading">¶</a></h2>
<p>[How is Accuracy calculated ?](<a class="reference external" href="https://github.com/OpenNMT/OpenNMT-py/issues/1944">https://github.com/OpenNMT/OpenNMT-py/issues/1944</a>)</p>
<p>[Discrepency between training and tranlsation](<a class="reference external" href="https://forum.opennmt.net/t/discrepency-between-training-and-tranlsation/4765">https://forum.opennmt.net/t/discrepency-between-training-and-tranlsation/4765</a>)</p>
</section>
</section>


          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2024, coconut.
              
          </div>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 7.3.7.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>