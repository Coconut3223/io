
å†³ç­–æ ‘
##########

==A decision tree== allows a classification of an object by testing its values for certain properties.

ç­–ç•¥ï¼šè‡ªé¡¶è€Œä¸‹ï¼Œåˆ†è€Œæ²»ä¹‹ï¼Œé€’å½’

.. danger:: å†³ç­–æ ‘æ²¡æœ‰ å­¦ä¹ ç‡se

.. note:: ""
    å·²çŸ¥è®­ç»ƒé›†  :math:`D=\{(x_1,y_1),\dots,(x_n,y_n)\}`  å±æ€§é›†  :math:`A=\{a_1,\dots,a_d\}` , å±æ€§å€¼é›†  :math:`a_i^v=\{a_i^1,\dots,a_i^v\}` 
    
    .. code-block:: python
        :linenos:

        def TreeGenerate(D, A):
            ç”Ÿæˆç»“ç‚¹ node
            if ALL node.D å±äº ä¸€ä¸ªç±»åˆ« C:
                node = C ç±»å¶ç»“ç‚¹  # åˆ†ç±»æˆåŠŸ
                return
            if node.A == NULL or node.D çš„æ ·æœ¬çš„å±æ€§å€¼éƒ½ä¸€æ ·:
                node = node.D ä¸­å¤šæ•°ç±» å¶ç»“ç‚¹  # ä¸èƒ½å†åˆ†
                return
            ä» node.A ä¸­é€‰æ‹©æœ€ä¼˜åˆ’åˆ†å±æ€§ a_best
            for v in a_best:
                åœ¨ node åº•ä¸‹ç”Ÿæˆåˆ†æ”¯ node_by_v
                if node_by_v == NULL:  # è®­ç»ƒé›†é‡Œæ²¡æœ‰ï¼Œä½†ä¸ºäº†æ³›åŒ–æ€§èƒ½
                    node_by_v = node.D ä¸­å¤šæ•°ç±» å¶ç»“ç‚¹
                    return
                TreeGenerate(D, A\{a_best})


    1. å¶å­ç»“ç‚¹æ˜¯æ ·æœ¬æ‰€å±çš„ç±»åˆ«
    2. é€’å½’ç»“æŸï¼šæ ‡è®°å¶ç»“ç‚¹ ==å¦‚ä½•åˆ¤å®šï¼šå¶å­ç»“ç‚¹==

       1. ç»“ç‚¹åŒ…å«åˆ†ç±»å…¨å±ä¸€ç±»ï¼š **åˆ†ç±»æˆåŠŸï¼Œèµ‹ç±»å€¼**
       2. ç»“ç‚¹çš„å±æ€§é›†Aä¸ºç©ºï¼Œç»“ç‚¹åŒ…å«çš„æ‰€æœ‰æ ·æœ¬åœ¨è¯¥ç»“ç‚¹çš„æ‰€æœ‰å±æ€§å€¼å–å€¼ç›¸åŒï¼š**æ— æ³•åˆ’åˆ†ï¼Œèµ‹è¯¥ç»“ç‚¹å¤šæ•°ç±»çš„ç±»å€¼**ï¼Œå½“å‰ç»“ç‚¹çš„åéªŒåˆ†å¸ƒã€‚
       3. ç»“ç‚¹çš„æ ·æœ¬é›†Dä¸ºç©ºï¼š**ä¸èƒ½åˆ’åˆ†ï¼Œèµ‹è¯¥çˆ¶ç»“ç‚¹å¤šæ•°ç±»çš„ç±»å€¼**ï¼ŒæŠŠçˆ¶ç»“ç‚¹çš„æ ·æœ¬åˆ†å¸ƒå½“ä½œå½“å‰ç»“ç‚¹çš„å…ˆéªŒåˆ†å¸ƒ

ä¼˜ç‚¹ï¼š

- éå‚æ•°æ–¹æ³•ï¼Œä¸è¦æ±‚ä»»ä½•å…ˆéªŒå‡è®¾ï¼Œä¸å‡å®šç±»å’Œå±æ€§æœä»ä¸€å®šæ¦‚ç‡åˆ†å¸ƒ
- å¯¹å™ªå£°æ•°æ®é²æ£’æ€§å¼º
- èƒ½è¡¨ç¤ºä¸ºå¤šæ¡ if-then çš„å†³ç­–è§„åˆ™ï¼Œå¯è§£é‡Šæ€§å¼º
- åˆ†ç±»é€Ÿåº¦å¿«ï¼Œæœ€åæƒ…å†µä¸‹æ˜¯ O(depth)
  
ç¼ºç‚¹ï¼š

- å¶ç»“ç‚¹å®ä¾‹æ•°ç›®å¤ªå°
- å¯¹ç¦»æ•£å€¼è¾ƒå¥½ï¼Œä½†è¿ç»­å€¼çš„æ¨¡æ‹Ÿè¡¨è¾¾ä¸å¤Ÿ
- å†³ç­–æ ‘æœ‰é‡å¤å¤šæ¬¡çš„å­æ ‘ï¼Œå› ä¸ºçº¯é å•ä¸ªå±æ€§æ¥åˆ†ï¼Œåœ¨å±æ€§ç©ºé—´çš„ä¸åŒéƒ¨åˆ†å¤šæ¬¡ä½¿ç”¨åŒä¸€ä¸ªå±æ€§æ¥åˆ’åˆ†

.. note:: å¦‚ä½•å¤„ç†ï¼šç¼ºå¤±å€¼ï¼Œè¿ç»­å˜é‡
    .. image:: ./pics/DT_2.png
        :scale: 30%


å¦‚ä½•åº¦é‡ï¼šæœ€ä½³åˆ’åˆ†
********************

| ==impurity, ä¸çº¯åº¦== ï¼Œåˆ†æ”¯ç»“ç‚¹æ‰€åŒ…å«æ ·æœ¬çš„å½’å±çš„åº¦é‡æŒ‡æ ‡ã€‚impurity â¬‡ï¸ï¼Œç±»åˆ†å¸ƒè¶Šå€¾æ–œã€‚
| ==Information Gain== . **ä¸çº¯åº¦çš„é™ä½ç¨‹åº¦**ï¼šç¡®å®šåˆ’åˆ†æ•ˆæœçš„åº¦é‡æ ‡å‡†ï¼šæœ€å¤§åŒ–å¢ç›Š :math:`\Delta` 

.. math::
    \max_{I}\Delta_{I}=I(\text{parent})-\sum_{i=1}^k\cfrac{N(j)}{N}I(j)\\\Leftrightarrow \min_I\sum_{i=1}^k\cfrac{N(j)}{N}I(j)

| :math:`k` : è¯¥å±æ€§ä¸åŒå–å€¼çš„ç§ç±»æ•°
| :math:`I(\text{parent})` : çˆ¶ç»“ç‚¹çš„ä¸çº¯åº¦,  :math:`N`  çˆ¶ç»“ç‚¹çš„æ ·æœ¬æ•°
| :math:`I(j)` : ç¬¬ j ä¸ªå­ç»“ç‚¹çš„ä¸çº¯åº¦,  :math:`N(j)`  ç¬¬ j ä¸ªå­ç»“ç‚¹çš„æ ·æœ¬æ•°


impurity
==========

.. table::

    +-----------+---------------------------+----+
    |Impurity   |                           |DT  |
    +===========+===========================+====+
    |ç†µ Entropy | :math:`p(i)\log_2p(i)`    |ID3 |
    +           +---------------------------+----+
    |           |å¼•å…¥åˆ†è£‚ä¿¡æ¯               |C4.5|
    +-----------+---------------------------+----+
    |Gini       | :math:`p(j)^2`            |CART|
    +-----------+---------------------------+----+
    |è¯¯åˆ†ç±»ç‡   | :math:`\max_ip(i\vert t)` |    |
    +-----------+---------------------------+----+

.. warning:: ä¸åŒçš„å‡†åˆ™å¯èƒ½å¯¼è‡´ä¸åŒçš„ç­”æ¡ˆ

ç†µ Entropy = ID3 â¡ï¸  C4.5
------------------------------

.. math::
    \text{Ent}(t)=-\sum_{i=1}^cp(i)\log_2p(i)

-  :math:`0\log_20=0` 
-  :math:`\max=0.5 \text{ å‡åŒ€åˆ†å¸ƒï¼Œ}\min=0 \text{ä»…å±äºä¸€ä¸ªç±»}` 

.. table::

    +----------------------+----------------------------------+----------------------------------+
    |attri                 |High Entropy                      |Low Entropy                       |
    +======================+==================================+==================================+
    |Variable distribution | uniform-like                     |many peaks and valleys            |
    +----------------------+----------------------------------+----------------------------------+
    |histogram             | Flat                             | many lows and highs              |
    +----------------------+----------------------------------+----------------------------------+
    |information           |less predictable Less information | more predictable More information|
    +----------------------+----------------------------------+----------------------------------+

.. grid:: 2

    .. grid-item::
        .. image:: ./pics/entropy_2.png
            :scale: 30%
            :align: center
    
    .. grid-item::
        .. image:: ./pics/entropy_1.png
            :scale: 30%
            :align: center

ç¼ºç‚¹ï¼šåå¥½é€‰æ‹©å…·æœ‰è¾ƒå¤šå±æ€§å€¼çš„å±æ€§ **é«˜ç†µåˆ†è£‚ï¼Œå¤§é‡å°éƒ¨åˆ†**

| ğŸ’¡è¯æ˜ **å°†ç»“ç‚¹åˆ’åˆ†ä¸ºæ›´å°çš„åç»­ç»“ç‚¹ï¼Œç»“ç‚¹ç†µä¸€å®šä¼šå‡å°‘æˆ–è€…ç»´æŒä¸å˜**ã€‚
| æ ¹æ®å®šä¹‰å¯çŸ¥ï¼Œç†µè¶Šå¤§ï¼Œç±»åˆ†å¸ƒè¶Šå‡åŒ€ï¼›ç†µè¶Šå°ï¼Œç±»åˆ†å¸ƒçº¦å€¾æ–œã€‚å‡è®¾åŸç»“ç‚¹å±äºå„ä¸ªç±»çš„æ¦‚ç‡ç›¸åŒ(çœŸå®åˆ†å¸ƒ)ï¼Œç†µ=1ï¼Œåˆ™åˆ†å‡ºæ¥çš„åç»­ç»“ç‚¹åœ¨å„ä¸ªç±»ä¸Šå‡åŒ€åˆ†å¸ƒï¼Œå„ä¸ªåç»­ç»“ç‚¹çš„ç†µ=1ï¼ŒåŠ æƒåç†µ ğŸŸ°ã€‚å‡è®¾åŸç»“ç‚¹å±äºå„ä¸ªç±»çš„æ¦‚ç‡ä¸ä¸€æ ·ï¼Œåˆ†å‡ºæ¥çš„åç»­ç»“ç‚¹ä¸å‡åŒ€åœ°åˆ†å¸ƒåœ¨å„ä¸ªç±»ä¸Šï¼Œåˆ™æ­¤æ—¶çš„åˆ†ç±»æ¯”åŸæœ‰çš„åˆ†ç±»æ›´ä¸å‡åŒ€ï¼Œæ‰€ä»¥ç†µ â¬‡ï¸

C4.5
^^^^^^^^^^

ä¸ºäº†æƒ©ç½š **é«˜ç†µåˆ†è£‚çš„å±æ€§**ï¼Œå¼•å…¥ **åˆ†è£‚ä¿¡æ¯ split information** çš„é¡¹  :math:`-\sum\limits_{j=1}^kp(j)\log_2p(j)`  ä½œä¸ºåˆ†æ¯ï¼Œé˜»ç¢é€‰æ‹©å±æ€§å€¼å‡åŒ€åˆ†å¸ƒçš„å±æ€§ã€‚ :math:`p(j)` :å½“å‰ç»“ç‚¹ä¸­åˆ’åˆ†å±æ€§ç¬¬jä¸ªå±æ€§å€¼æ‰€å æœ‰æ ·æœ¬çš„æ¯”ä¾‹ã€‚

.. math:: 
    \begin{align*}\text{GainRatio}(t)&=\cfrac{\Delta_I}{-\sum\limits_{j=1}^kp(j)\log_2^p(j)}\\&=\cfrac{\sum\limits_{i=1}^cp_p(i)\log_2p_p(i)-\sum\limits_{j=1}^c\cfrac{N(j)}{N}\cdot\sum\limits_{i=1}^cp_j(i)\log_2p_j(i)}{-\sum\limits_{j=1}^kp_p(j)\log_2p_p(j)}\end{align*} :math:`` 

- <u>Q:</u> å½“åˆ’åˆ†å±æ€§åœ¨å½“å‰ç»“ç‚¹ä¸­å‡ ä¹ç›¸åŒçš„å±æ€§å€¼æ—¶ï¼Œä¼šå¯¼è‡´å¢ç›Šæ— å®šä¹‰æˆ–è€…éå¸¸å¤§(åˆ†æ¯éå¸¸å°ç”šè‡³ä¸º0)ã€‚åå¥½é€‰æ‹©å…·æœ‰è¾ƒå°‘å±æ€§å€¼çš„å±æ€§ã€‚
    Aï¼šå¯å‘å¼æ–¹æ³•ã€‚å…ˆè®¡ç®—æ¯ä¸ªå±æ€§çš„ä¿¡æ¯å¢ç›ŠåŠå¹³å‡å€¼ï¼Œç„¶åä»…å¯¹ä¿¡æ¯å¢ç›Šé«˜äºå¹³å‡å€¼çš„å±æ€§åº”ç”¨å¢ç›Šç‡åº¦é‡ã€‚
    
Gini åŸºå°¼ç³»æ•°
---------------

.. math::
    \text{Gini}(t)=1-\sum_{j=1}^kp(j)^2 

| **proof: å¹³å‡åˆ†é… 1/2 worst**
| å‡è®¾æœ‰ä¸¤ç±»  :math:`\text{Gini}(t)=1-x^2-(1-x)^2=2x-2x^2` 
| :math:`\frac{b}{2a}=\frac{1}{2}`  å¼€å£å‘ä¸‹ï¼Œæ­¤æ—¶æ˜¯æœ€é«˜ç‚¹ã€‚

è¯¯åˆ†ç±»ç‡
----------

.. math::
    \text{Error}(t)=1-\max_ip(i|t) 

:math:`\max=1-\frac{1}{c} \text{ å‡åŒ€åˆ†å¸ƒï¼Œ}\min=0 \text{ä»…å±äºä¸€ä¸ªç±»}` 

.. hint:: node: +:5; -:1
    | :math:`\text{Gini}(t)=1-\frac{1}{6}^2-\frac{5}{6}^2=0.278` 
    | :math:`\text{Ent}(t)=-\frac{1}{6}\log_2\frac{1}{6}-\frac{5}{6}\log_2\frac{5}{6}=1.650` 
    | :math:`\text{Error}(t)=1-\frac{5}{6}=0.167` 

.. hint:: node: +:3, -:3
    | :math:`\text{Gini}(t)=1-\frac{1}{2}^2-\frac{1}{2}^2=0.5` 
    | :math:`\text{Ent}(t)=-\frac{1}{2}\log_2\frac{1}{2}-\frac{1}{2}\log_2\frac{1}{2}=1` 
    | :math:`\text{Error}(t)=1-\frac{1}{2}=0.5` 

.. hint:: Exercise. Consider the following data set for a binary class problem.
    | (a). Calculate the **entropy** gain when splitting on A and B. Which attribute would the decision tree induction algorithm choose?
    | (b). Calculate the gain in the **Gini** index when splitting on A and B. Which attribute would the decision tree induction algorithm choose?
    | A F T T F T F F F T F
    | B T T T T T F F F T T
    | L + + + âˆ’ + âˆ’ âˆ’ âˆ’ âˆ’ âˆ’
    | I 1 2 3 4 5 6 7 8 9 10

    | A T:7(+:4;-:3) F:3(+:0;-:3)
    | B T:4(+:3;-:1) F:6(+:1;-:5)
    
    | Entropy
    | :math:`\text{Ent}(A)=\frac{7}{10}(-\frac{4}{7}\log_2\frac{4}{7}-\frac{3}{7}\log_2\frac{3}{7})+\frac{3}{10}\times0=0.6897`  (smaller  :math:`\implies A` )
    | :math:`\text{Ent}(B)=\frac{2}{5}(-\frac{3}{4}\log_2\frac{3}{4}-\frac{1}{4}\log_2\frac{1}{4})+\frac{3}{5}(-\frac{1}{6}\log_2\frac{1}{6}-\frac{5}{6}\log_2\frac{5}{6})=0.7145` 
    
    | Gini
    | :math:`\text{Gini}(A)=\frac{7}{10}(1-\frac{4}{7}^2-\frac{3}{7}^2)+\frac{3}{10}\times0=\frac{12}{35}` 
    | :math:`\text{Gini}(B)=\frac{2}{5}(1-\frac{3}{4}^2-\frac{1}{4}^2)+\frac{3}{5}(1-\frac{1}{6}^2-\frac{5}{6}^2)=\frac{19}{60}`  (smaller  :math:`\implies B` )

performance
===============

| **Not too small**: need to handle important but possibly subtle distinctions in  data
| **Not too big**: Computational efficiency (avoid redundant, spurious attributes),Avoid over-fitting training examples
| ==Occamâ€™s Razor== : find the simplest hypothesis (smallest tree) that fits the  observations.  **The best decision tree** is the smallest one that correctly classifies all given examples.

è¿‡æ‹Ÿåˆ
----------

over-fitting due to

- presence of noise
- lack of representative samples

.. table::

    +----+----------------+--------------------------------------------------------------+
    |ç­–ç•¥|                |å®šä¹‰                                                          |
    +====+================+==============================================================+
    |å‰ªæ|pre-pruning     |åœ¨ç®—æ³•å®Œç¾åˆ’åˆ†è®­ç»ƒæ•°æ®å‰å°±åœæ­¢æ ‘çš„ç”Ÿé•¿ï¼ˆåŸºäºæ€§èƒ½ï¼Œæ¯”è¾ƒè½¯æ€§    |
    +    +----------------+--------------------------------------------------------------+
    |    |post-pruning    |å…è®¸æ ‘è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œç„¶åå¯¹æ ‘è¿›è¡Œåä¿®å‰ªã€‚æ›´æˆåŠŸ            |
    +----+----------------+--------------------------------------------------------------+
    |     æŠŠå¤æ‚åº¦åŠ å…¥è€ƒé‡|ä½¿ç”¨ä¸€ä¸ªæ˜ç¡®çš„æ ‡å‡†æ¥è¡¡é‡å†³ç­–æ ‘çš„å¤æ‚åº¦ï¼ˆå†³ç­–æ ‘çš„æ·±åº¦ï¼Œæ¯”è¾ƒç¡¬æ€§|
    +----+----------------+--------------------------------------------------------------+

- åå‰ªæé€šå¸¸æ¯”é¢„å‰ªæä¿ç•™æ›´å¤šçš„<u>åˆ†æ”¯æ•°</u>ã€‚
- åå‰ªæçš„<u>æ¬ æ‹Ÿåˆé£é™©</u>æ›´å°ï¼Œ<u>æ³›åŒ–æ€§èƒ½</u>é€šå¸¸ä¼˜äºé¢„å‰ªæã€‚
- åå‰ªææ˜¯åœ¨ç”Ÿæˆå®Œå…¨å†³ç­–æ ‘ä¹‹åè¿›è¡Œï¼Œå¹¶ä¸”è¦è‡ªåº•å‘ä¸Šåœ°å¯¹æ ‘ä¸­æ‰€æœ‰éå¶ç»“ç‚¹è¿›è¡Œé€ä¸€è€ƒå¯Ÿï¼Œ<u>è®­ç»ƒæ—¶é—´</u>è¿œå¤§äºé¢„å‰ªæã€‚

é¢„å‰ªæ, pre-pruning
--------------------

- ç»“ç‚¹å®ä¾‹æ•°ç›®å°äºé¢„å®šä¹‰çš„é˜ˆå€¼
- å®ä¾‹ç±»åˆ†å¸ƒä¸å±æ€§å€¼ç›¸äº’ç‹¬ç«‹  :math:`\leftarrow\Chi^2` æ£€éªŒ
- å½“å‰ç»“ç‚¹çš„æ‰©å±•ä¸èƒ½å‡å°ä¸çº¯åº¦

åå‰ªæ, post-pruning
-------------------------

- è‡ªä¸Šè€Œä¸‹ä¿®å‰ª
- è‹¥å‰ªææ”¹å–„æ³›åŒ–è¯¯å·®ï¼Œåˆ™æ”¹ç»“ç‚¹ä»£æ›¿å­æ ‘
- å­æ ‘çš„å¶å®ä¾‹çš„ä¸»è¦ç±»ç¡®å®šèŠ‚ç‚¹çš„ç±»æ ‡ç­¾
- åœ¨åå‰ªæä½¿ç”¨ MDLï¼Œæœ€å°æè¿°é•¿åº¦

å¤šå˜é‡å†³ç­–æ ‘ multivariate decision tree
****************************************

.. grid:: 2

    .. grid-item::
        :columns: 3
        
        è‹¥æˆ‘ä»¬æŠŠæ¯ä¸ªå±æ€§æ˜¯ä¸ºåæ ‡ç©ºé—´çš„ä¸€ä¸ªåæ ‡è½´ï¼Œåˆ™dä¸ªå±æ€§å€¼æè¿°çš„æ ·æœ¬å¯¹åº”äº†dç»´ç©ºé—´çš„ä¸€ä¸ªå…·ä½“çš„æ•°æ®ç‚¹ï¼Œå¯¹æ ·æœ¬çš„åˆ†ç±» å…¶å®æ˜¯åœ¨è¿™ä¸ªæ ·æœ¬ç©ºé—´ä¸­å¯»æ‰¾ä¸åŒç±»æ ·æœ¬ä¹‹é—´çš„åˆ†ç±»è¾¹ç•Œã€‚

    .. grid-item::
        :columns: 9
        
        .. image:: ./pics/DT_1.png
            :scale: 25%
            :align: center

.. table::

    +----------+----------------------------------------------+-----------------------------------+
    |          |å•å˜é‡ DT                                     | å¤šå˜é‡ DT                         |
    +==========+==============================================+===================================+
    |åˆ†ç±»è¾¹ç•Œ  | è½´å¹³è¡Œ                                       |æ–œçš„ï¼Œæ›²çº¿                         |
    +          +----------------------------------------------+                                   +
    |          |åˆ†ç±»è¾¹ç•Œç”±è‹¥å¹²ä¸ªã€ä¸åæ ‡è½´å¹³è¡Œçš„åˆ†æ®µã€‘ç»„æˆ    |                                   |
    +----------+----------------------------------------------+-----------------------------------+
    |åˆ†ç±»æŒ‡æ ‡ï¼š|å•ä¸ªå±æ€§                                      |å±æ€§çš„çº¿æ€§ç»„åˆ                     |
    +          +----------------------------------------------+-----------------------------------+
    |          |ä¸ºæ¯ä¸ªéå¶ç»“ç‚¹æ‰¾ä¸€ä¸ªæœ€ä¼˜åˆ’åˆ†å±æ€§              | :math:`\sum\limits_{i=1}^dw_ia_i` |
    +----------+----------------------------------------------+-----------------------------------+
    |è¡¨ç°      |åœ¨çœŸå®åˆ†ç±»è¾¹ç•Œè¾ƒä¸ºå¤æ‚çš„æƒ…å†µä¸‹ï¼Œéœ€è¦          |æ¨¡å‹ç®€å•ï¼Œä½†è¾ƒéš¾è§£é‡Š               |
    +          +----------------------------------------------+                                   +
    |          |å¤§é‡çš„å±æ€§æµ‹è¯•å’Œå¾ˆæ·±çš„å†³ç­–æ ‘æ‰èƒ½è·å¾—è¾ƒå¥½çš„è¿‘ä¼¼|                                   |
    +----------+----------------------------------------------+-----------------------------------+
